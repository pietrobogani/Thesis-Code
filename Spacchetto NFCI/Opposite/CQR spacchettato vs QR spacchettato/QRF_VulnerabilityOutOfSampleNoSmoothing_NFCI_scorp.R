# Install and load necessary packages
library(quantreg)
library(lubridate)
library(pracma)
library(readxl)
library(sn)
library(quantreg)


# Clear workspace 
rm(list = ls())

# Load the functions
source("C:/Users/Pietro/Desktop/Pietro/Politecnico/Tesi/Thesis-Code/functions.R")


# Set forecast horizon (run script separately for h = 1 and h = 4)
h <-4 




loadsavedresults = FALSE; # If I run code already and results are stored in ResOOS_H



# Graphics settings - R's graphics system differs from MATLAB's, so some modifications are necessary
par(mfrow = c(1, 1))  # Reset plot window to single pane



# Load data 
file_path <- "Data_adj.xls"

# Read the file
data <- read_excel(file_path)
data<-data[,-c(3:10)]

# Filter data for 1973Q1-2015Q4
colnames(data)[1] <- "Time"
data$Time <- as.Date(data$Time)


# Subset the data
data <- data[data$Time >= as.Date("1973-01-01") & data$Time <= as.Date("2015-10-01"), ]
X <- data[,-1]
Time <- data$Time


# Set forecast settings
#QQ <- seq(0.05, 0.95, by = 0.05)
QQ <- seq(0.01, 0.99, by = 0.01) #Let's try a much more fine grid 
#QQ <- c(0.01, QQ, 0.99)
deltaYY <- 0.1
YY <- seq(-20, 20, by = deltaYY)
jtFirstOOS <- which(year(data$Time) == 1993 & month(data$Time) == 1)    #81
indices <- which(QQ %in% c(0.05, 0.25, 0.5, 0.75, 0.95))
jq05 <- indices[1]
jq25 <- indices[2]
jq50 <- indices[3]
jq75 <- 16 #couldn't automatically translate from MATLAB, I set it manually, no idea why
jq95 <- indices[4]

# Construct average growth rates
y <- X$A191RL1Q225SBEA
Yh <- matrix(0, nrow=length(y), ncol=4)


Yh <- stats::filter(y, rep(1/h, h), sides=1) #If h = 1, y = Yh
if (h>1){
  Yh[1:(h-1)] <- NA
}
              
hist(y)

#Construct matrices of regressors
Z <- cbind(1, X[,-1], y)
ZGDPonly <- cbind(1, y)
Z <-as.matrix(Z)












#if (loadsavedresults == FALSE) {

#----------------------- In-sample and out-of-sample estimation/forecasting

{
# Get length of Time and QQ/YY
len_time <- length(data$Time)
len_qq <- length(QQ)
len_yy <- length(YY)

# Initialize matrices to store forecasts

# Raw quantiles
YQ_NaNs <- matrix(NA, len_time, len_qq)
YQ_ISNS <- YQ_NaNs
YQ_OOSNS <- YQ_NaNs
YQGDPonly_ISNS <- YQ_NaNs
YQGDPonly_OOSNS <- YQ_NaNs
YQunc_ISNS <- YQ_NaNs
YQunc_OOSNS <- YQ_NaNs

# PDFs (evaluated over grid)
P_NaNs <- matrix(NA, len_time, len_yy)
PST_ISNS <- P_NaNs
PST_OOSNS <- P_NaNs
PSTGDPonly_ISNS <- P_NaNs
PSTGDPonly_OOSNS <- P_NaNs
PSTunc_ISNS <- P_NaNs
PSTunc_OOSNS <- P_NaNs

# Smoothed quantiles
Q_NaNs <- matrix(NA, len_time, len_qq)
QST_ISNS <- Q_NaNs
QST_OOSNS <- Q_NaNs
QSTGDPonly_ISNS <- Q_NaNs
QSTGDPonly_OOSNS <- Q_NaNs
QSTunc_ISNS <- Q_NaNs
QSTunc_OOSNS <- Q_NaNs

# CDFs (evaluated over grid)
C_NaNs <- matrix(NA, len_time, len_yy)
CST_ISNS <- C_NaNs
CST_OOSNS <- C_NaNs
CSTGDPonly_ISNS <- C_NaNs
CSTGDPonly_OOSNS <- C_NaNs
CSTunc_ISNS <- C_NaNs
CSTunc_OOSNS <- C_NaNs

# Skewed t-distribution parameters
STpar_NaNs <- matrix(NA, len_time, 4)
STpar_ISNS <- STpar_NaNs
STpar_OOSNS <- STpar_NaNs
STparGDPonly_ISNS <- STpar_NaNs
STparGDPonly_OOSNS <- STpar_NaNs
STparunc_ISNS <- STpar_NaNs
STparunc_OOSNS <- STpar_NaNs

# Predictive scores
Score_NaNs <- rep(NA, len_time)
ScoreST_ISNS <- Score_NaNs
ScoreST_OOSNS <- Score_NaNs
ScoreSTGDPonly_ISNS <- Score_NaNs
ScoreSTGDPonly_OOSNS <- Score_NaNs
ScoreSTunc_ISNS <- Score_NaNs
ScoreSTunc_OOSNS <- Score_NaNs

# Probability integral transforms
Pit_NaNs <- rep(NA, len_time)
PitST_ISNS <- Pit_NaNs
PitST_OOSNS <- Pit_NaNs
PitSTGDPonly_ISNS <- Pit_NaNs
PitSTGDPonly_OOSNS <- Pit_NaNs
PitSTunc_ISNS <- Pit_NaNs
PitSTunc_OOSNS <- Pit_NaNs

# Left entropy
Entropy_NaNs <- rep(NA, len_time)
LeftEntropy_ISNS <- Entropy_NaNs
LeftEntropy_OOSNS <- Entropy_NaNs

}



#-------------------    %% In-sample estimation of conditional quantiles
Ztemp <- Z[, apply(Z, 2, function(x) var(x) > 1e-5)] #ci sono colonne uguali che non voglio  

qrf_model <- quantregForest(x = Ztemp[1:(length(Yh) - h),], y = Yh[(h + 1):length(Yh)])
qrf_modelGDPonly <- quantregForest(x = as.matrix(ZGDPonly[1:(length(Yh) - h),-1]), y = Yh[(h + 1):length(Yh)])

{
# In-sample estimation of conditional quantiles

for (jq in 1:length(QQ)) {

    YQ_ISNS[(h + 1):length(Yh), jq] <- predict(qrf_model, newdata = Ztemp[1:(length(Yh) - h),], what = (1-QQ[jq]))

  # Quantile regression with GDP only
  YQGDPonly_ISNS[(h + 1):length(Yh), jq] <-  predict(qrf_modelGDPonly, newdata = as.matrix(ZGDPonly[1:(length(Yh) - h),-1]), what = (1-QQ[jq]))
  
  # Unconditional quantiles (quantile regression on constant)
  bunc <- rq(Yh[(h + 1):length(Yh)] ~ 1, tau=QQ[jq])
  YQunc_ISNS[(h + 1):length(Yh), jq] <- rep(coef(bunc), length(Time) - h)
}
  
}


#---------    %% Fit skewed-t distribution for in-sample unconditional quantiles
{

  qqTarg <- YQunc_ISNS[nrow(YQunc_ISNS), ]
  
  
  # Assign values to matrices based on the skewed-t fit
  densities <- dst(YY, QQ, qqTarg) # PROBLEMA! visto che ho solo quantili empirici, sotto quantile 0.05 e sopra 0.95 assegno densità =0. Cosa che con smoothing non succede. Come risolvere?
  plot(YY,densities) #forma assomiglia a quella originale, un po' skewed a destra
  replicated_matrix <- matrix(rep(densities, each = length(Time) - h), ncol = length(densities))
  PSTunc_ISNS[(h + 1):nrow(PSTunc_ISNS), ] <- replicated_matrix #Giusto, ma tanti 0, forse troppi che danno problemi

  
  densities <- qst(QQ, qqTarg) #diverso dall'originale che invece dava i quantili dopo smoothing
  plot(QQ,densities, ylab = 'empirical quantiles') #anche questo simile
  replicated_matrix <- matrix(rep(densities, each = length(Time) - h), ncol = length(densities))
  QSTunc_ISNS[(h + 1):nrow(QSTunc_ISNS), ] <- replicated_matrix #Credo giusto
  
  
  densities <- pst(YY, QQ, qqTarg)
  plot(YY, densities, ylab = 'empirical cumulative') #molto molto simile all'originale
  replicated_matrix <- matrix(rep(densities, each = length(Time) - h), ncol = length(densities))
  CSTunc_ISNS[(h + 1):nrow(CSTunc_ISNS), ] <- replicated_matrix #giusto, ma pochi valori xk step function 
  
  
  #STparunc_ISNS[(h + 1):nrow(STparunc_ISNS), ] <- matrix(rep(c(lc, sc, sh, df), times = length(Time) - h), 
  #                                                   nrow = length(Time) - h, 
  #                                                   byrow = TRUE)
  #Questo semplicemente salva i parametri, non mi serve più
  
  
  ScoreSTunc_ISNS[(h + 1):length(Yh)] <- dst(Yh[(h + 1):length(Yh)], QQ, qqTarg) #corretto
  plot(Yh[(h + 1):length(Yh)],ScoreSTunc_ISNS[(h + 1):length(Yh)], xlab = 'real observations', ylab = 'scores')
  PitSTunc_ISNS[(h + 1):length(Yh)] <- pst(Yh[(h + 1):length(Yh)], QQ, qqTarg)
  plot(Yh[(h + 1):length(Yh)],PitSTunc_ISNS[(h + 1):length(Yh)], xlab = 'real observations',ylab = 'empirical cumulative')
}

#---------------------    %% Fit t-densities for in-sample and out-of-sample estimation
{

for (jt in 1:(length(Time) - h)) {
  
  month_val <- as.numeric(format(Time[jt], "%m"))
  year_val <- as.numeric(format(Time[jt], "%Y"))
  
  if (month_val == 1 && jt >= jtFirstOOS) {
    cat(sprintf("Computing in-sample and out-of-sample predictive densities in %d", year_val), "\n")
  } else {
    cat(sprintf("Computing in-sample predictive densities in %d", year_val), "\n")
  }
  
  YhRealized <- Yh[jt + h]
  
  qqTarg <- YQ_ISNS[jt + h, ]
  PST_ISNS[jt + h, ] <- dst(YY, QQ, qqTarg) 
  QST_ISNS[jt + h, ] <- qst(QQ, qqTarg)
  CST_ISNS[jt + h, ] <- pst(YY, QQ, qqTarg)
  #STpar_ISNS[jt + h, ] <- c(lc, sc, sh, df)
  ScoreST_ISNS[jt + h ] <- dst(YhRealized, QQ, qqTarg)
  PitST_ISNS[jt + h ] <- pst(YhRealized, QQ, qqTarg)   #pressochè identico all'originale 
  
  Temp <- PST_ISNS[jt + h, ] * (YY < QST_ISNS[jt + h, jq50])
  
  non_zero_indexes <- (PSTunc_ISNS[jt + h, ]!= 0) & (PST_ISNS[jt + h, ] != 0) #I keep only the values where both the cond and uncond dens are non zero
  
  # Create new vectors with values from those indexes
  PSTunc_ISNS_non_zero <- PSTunc_ISNS[jt + h, ][non_zero_indexes]
  PST_ISNS_non_zero <- PST_ISNS[jt + h, ][non_zero_indexes]
  Temp_non_zero <- Temp[non_zero_indexes]
  
  LeftEntropy_ISNS[jt + h] <- -sum((log(PSTunc_ISNS_non_zero) - log(PST_ISNS_non_zero)) * Temp_non_zero * deltaYY) 
  
  
  
  # Similar computations for GDP only
  qqTarg_GDPonly <- YQGDPonly_ISNS[jt + h, ]

  
  PSTGDPonly_ISNS[jt + h, ] <- dst(YY, QQ, qqTarg_GDPonly)
  QSTGDPonly_ISNS[jt + h, ] <- qst(QQ, qqTarg_GDPonly)
  CSTGDPonly_ISNS[jt + h, ] <- pst(YY, QQ, qqTarg_GDPonly)
  #STparGDPonly_ISNS[jt + h, ] <- c(lc, sc, sh, df)
  ScoreSTGDPonly_ISNS[jt + h] <- dst(YhRealized, QQ, qqTarg_GDPonly)
  PitSTGDPonly_ISNS[jt + h] <- pst(YhRealized, QQ, qqTarg_GDPonly) # is the probability to observe a value < of YhRealized in this distribution 
  
  

  
  if (jt >= jtFirstOOS) {
    if (month(Time[jt]) == 1) {
      cat(sprintf("Now computing the real-time predictive densities in %d", year(Time[jt])), "\n")
    }
    
    
    Ztemp <- Z
    Ztemp <- Ztemp[, apply(Ztemp[1:(jt-h),], 2, function(x) var(x) > 1e-5)] #ci sono colonne uguali che non voglio 
    
    
    #TOLGO COLONNE TROPPO CORRELATE
    ret <- remove_highly_correlated(Ztemp)
    Ztemp <- ret$cleaned_data
    col_to_remove <- ret$removed_indices
    
    
    #DEVO TOGLIERE COLONNE SE HO PIU' COLONNE CHE OSSERVAZIONI
    ret <- remove_excess_columns(Ztemp)
    Ztemp <- ret$modified_matrix
    
    qrf_model <- quantregForest(x = Ztemp[1:(jt - h),], y = Yh[(h + 1):jt])
    qrf_modelGDPonly <- quantregForest(x = as.matrix(ZGDPonly[1:(jt- h),-1]), y = Yh[(h + 1):jt])
    
    
    for (jq in 1:length(QQ)) {   
      
      YQ_OOSNS[jt + h, jq] <- predict(qrf_model, newdata = Ztemp[jt,], what = (1-QQ[jq])) 

      # Quantile regression with GDP only, out-of-sample
      YQGDPonly_OOSNS[jt + h, jq] <- predict(qrf_modelGDPonly, newdata = as.matrix(ZGDPonly[jt,-1]), what = (1-QQ[jq])) 
      
      # Unconditional quantiles, out-of-sample
      bunc <- rq(Yh[(h + 1):jt ] ~ 1, QQ[jq])
      YQunc_OOSNS[jt + h, jq] <- coef(bunc)
      #YQunc_ISNS[(h + 1):length(Yh), jq] <- rep(coef(bunc), length(Time) - h)
    }
    
    
    #params <- QQInterpolation_env$QQInterpolation(YQ_OOSNS[jt + h, ], QQ) #YQ_OOSNS[jt + h, ] is the new qqTarg!
    PST_OOSNS[jt + h, ] <- dst(YY, QQ, YQ_OOSNS[jt + h, ])
    QST_OOSNS[jt + h, ] <- qst(QQ, YQ_OOSNS[jt + h, ])
    CST_OOSNS[jt + h, ] <- pst(YY, QQ, YQ_OOSNS[jt + h, ])
    #STpar_OOSNS[jt + h, ] <- c(params$lc, params$sc, params$sh, params$df)
    ScoreST_OOSNS[jt + h] <- dst(YhRealized, QQ, YQ_OOSNS[jt + h, ])
    PitST_OOSNS[jt + h] <- pst(YhRealized, QQ, YQ_OOSNS[jt + h, ]) # is the probability to observe a value < of YhRealized in this distribution 
    
    #params_GDPonly <- QQInterpolation_env$QQInterpolation(YQGDPonly_OOSNS[jt + h, ], QQ)
    PSTGDPonly_OOSNS[jt + h, ] <- dst(YY, QQ, YQGDPonly_OOSNS[jt + h, ])
    QSTGDPonly_OOSNS[jt + h, ] <- qst(QQ, YQGDPonly_OOSNS[jt + h, ])
    CSTGDPonly_OOSNS[jt + h, ] <- pst(YY, QQ, YQGDPonly_OOSNS[jt + h, ])
    #STparGDPonly_OOSNS[jt + h, ] <- c(params_GDPonly$lc, params_GDPonly$sc, params_GDPonly$sh, params_GDPonly$df)
    ScoreSTGDPonly_OOSNS[jt + h] <- dst(YhRealized, QQ, YQGDPonly_OOSNS[jt + h, ])
    PitSTGDPonly_OOSNS[jt + h] <- pst(YhRealized, QQ, YQGDPonly_OOSNS[jt + h, ]) # is the probability to observe a value < of YhRealized in this distribution 
    
    #params_unc <- QQInterpolation_env$QQInterpolation(YQunc_OOSNS[jt + h, ], QQ)
    PSTunc_OOSNS[jt + h, ] <- dst(YY, QQ, YQunc_OOSNS[jt + h, ])
    QSTunc_OOSNS[jt + h, ] <- qst(QQ, YQunc_OOSNS[jt + h, ])
    CSTunc_OOSNS[jt + h, ] <- pst(YY, QQ, YQunc_OOSNS[jt + h, ])
    #STparunc_OOSNS[jt + h, ] <- c(params_unc$lc, params_unc$sc, params_unc$sh, params_unc$df)
    ScoreSTunc_OOSNS[jt + h] <- dst(YhRealized, QQ, YQunc_OOSNS[jt + h, ])
    PitSTunc_OOSNS[jt + h] <- pst(YhRealized, QQ, YQunc_OOSNS[jt + h, ]) # is the probability to observe a value < of YhRealized in this distribution 
    
    # Compute entropy for skewed t-distribution from quantile regression with GDP and NFCI, out-of-sample
    Temp <- PST_OOSNS[jt + h, ] * (YY < QST_OOSNS[jt + h, jq50])
    
    non_zero_indexes <- (PSTunc_OOSNS[jt + h, ] != 0) & (PST_OOSNS[jt + h, ] != 0)
    
    # Create new vectors with values from those indexes
    PSTunc_OOSNS_non_zero <- PSTunc_OOSNS[jt + h, ][non_zero_indexes]
    PST_OOSNS_non_zero <- PST_OOSNS[jt + h, ][non_zero_indexes]
    Temp_non_zero <- Temp[non_zero_indexes]
    
    LeftEntropy_OOSNS[jt + h] <- -sum((log(PSTunc_OOSNS_non_zero) - log(PST_OOSNS_non_zero)) * Temp_non_zero * deltaYY)
    }
  
} 

}
  
  
    filename <- paste("ResOOSNSQRFspacchetto_H", h, ".RData", sep="")
    cat(paste("Saving results to file", filename, "\n"))
    
    # Save all the variables to the .RData file
    save(
      YQ_ISNS,      YQ_OOSNS,      YQGDPonly_ISNS,      YQGDPonly_OOSNS,      YQunc_ISNS,      YQunc_OOSNS,
      PST_ISNS,     PST_OOSNS,     PSTGDPonly_ISNS,     PSTGDPonly_OOSNS,     PSTunc_ISNS,     PSTunc_OOSNS,
      QST_ISNS,     QST_OOSNS,     QSTGDPonly_ISNS,     QSTGDPonly_OOSNS,     QSTunc_ISNS,     QSTunc_OOSNS,
      CST_ISNS,     CST_OOSNS,     CSTGDPonly_ISNS,     CSTGDPonly_OOSNS,     CSTunc_ISNS,     CSTunc_OOSNS,
      STpar_ISNS,   STpar_OOSNS,   STparGDPonly_ISNS,   STparGDPonly_OOSNS,   STparunc_ISNS,   STparunc_OOSNS,
      ScoreST_ISNS, ScoreST_OOSNS, ScoreSTGDPonly_ISNS, ScoreSTGDPonly_OOSNS, ScoreSTunc_ISNS, ScoreSTunc_OOSNS,
      PitST_ISNS,   PitST_OOSNS,   PitSTGDPonly_ISNS,   PitSTGDPonly_OOSNS,   PitSTunc_ISNS,   PitSTunc_OOSNS,
      LeftEntropy_ISNS, LeftEntropy_OOSNS, 
      file=filename
    )
  
    
     # rm(filename)  # equivalent to MATLAB's clear('filename')
 # 
 # 
 # #}
 # 
 # filename <- paste("ResOOSNS_H", h, ".RData", sep="")
 # cat(paste("Loading results from file", filename, "\n"))
 # 
 # load(filename)

#------------------------------

PITtest_env <- new.env()
source("PITtest.r",local = PITtest_env)

rstestboot_env <- new.env()
source("rstestboot.r",local = rstestboot_env)







# Figure 10. Out-of-sample Predictions.         
 
# (a)/(b) Quantiles
par(mar = c(3, 3, 2, 1))  # Adjust the values as needed (bottom, left, top, right)

plot(Time, YQ_OOSNS[, jq05], type = 'l', col = 'blue', xlab = 'Time', ylab = 'Quantiles', xlim = range(Time),ylim = c(-20,20))
lines(Time, YQ_OOSNS[, jq50], type = 'l', col = 'blue', lty = 2)
lines(Time, YQ_OOSNS[,jq95], type = 'l', col = 'blue', lty = 3) 
lines(Time, YQ_ISNS[, jq05], type = 'l', col = 'black', lty = 1)
lines(Time, YQ_ISNS[, jq50], type = 'l', col = 'black', lty = 2)
lines(Time, YQ_ISNS[, jq95], type = 'l', col = 'black', lty = 3)





# (c)/(d) Downside Entropy
plot(Time, LeftEntropy_OOSNS, type = 'l', col = 'blue', 
     xlab = 'Time', ylab = 'Entropy', xlim = range(Time))
lines(Time, LeftEntropy_ISNS, type = 'l', col = 'black', lty = 2)



# Figure 11. Out-of-sample Accuracy.   
# (a)/(b) Predictive scores
plot(Time, ScoreST_OOSNS, type = 'l', col = 'blue', xlab = 'Time', ylab = 'Scores')
lines(Time, ScoreSTGDPonly_OOSNS, type = 'l', col = 'black', lty = 2)
legend('topleft', legend = c('GDP and NFCI', 'GDP only'))



# (c)/(d): PITs #CORRETTO anche dopo parallelizione di QuantInterp!!!!!!!!!!!!!
# The code below was modified from files provided by Barbara Rossi and
# Tatevik Sekhposyan implementing the specification tests for predictive
# densities described in Rossi and Sekhposyan (2017).
rvec <- seq(0, 1, by = 0.001)
zST_ecdf1 <- PITtest_env$PITtest(PitST_OOSNS, rvec)
CnSS_model <- 1 - mean((zST_ecdf1 - seq(0, 1, length.out = length(zST_ecdf1)))^2) / var(zST_ecdf1) # h = 4: 0.55658995 || h = 1: 0.7951442  is the value. 1 is perfect calibrated
mean_squared_diff <- mean((zST_ecdf1-rvec)^2) # h = 4: 0.03382078 || h = 1: 0.01705973


zSTGDPonly_ecdf1 <- PITtest_env$PITtest(PitSTGDPonly_OOSNS, rvec)
CnSS_model_GDPonly <- 1 - mean((zSTGDPonly_ecdf1 - seq(0, 1, length.out = length(zSTGDPonly_ecdf1)))^2) / var(zSTGDPonly_ecdf1) # h = 4: 0.92477 || h = 1:  0.9237593 is the value. 1 is perfect calibrated
mean_squared_diff_GDPonly <- mean((zSTGDPonly_ecdf1-rvec)^2) # h = 4: 0.008269042 || h = 1: 0.008313394


if (h == 1) {
  # Use asymptotic 5% critical value from Rossi and Sekhposyan (2017): 1.34
  kappa <- 1.34
  kappaGDPonly <- 1.34
  
} else if (h == 4) {
  # Compute bootstrapped 5% critical values
  PITs <- cbind(PitST_OOSNS, PitSTGDPonly_OOSNS)
  PITs <- PITs[(jtFirstOOS + h):nrow(PITs), , drop = FALSE]
  
  #testcritvalues <- matrix(NA, nrow = 1, ncol = 2, dimnames = list(NULL, c('GDP and NFCI', 'GDP only')))
  testcritvalues <- array(NA, dim = c(2, 3, 2))
  
  for (i in 1:2) {
    testcritvalues[,, i] <- round(rstestboot_env$rstestboot(PITs[, i])$critvalues[2] * 100) / 100
  }
  
  kappa <- testcritvalues[1, 2, 1] #different from Matlab due to seed in CVfinalbootstrapInoue
  kappaGDPonly <- testcritvalues[1, 2, 2] #different from Matlab due to seed in CVfinalbootstrapInoue
}

# Plot PIT for full quantile regression vs. quantile regression with GDP only
plot(rvec, zST_ecdf1, type = 'l', col = 'blue', xlab = 'tau', ylab = 'Empirical CDF')
lines(rvec, zSTGDPonly_ecdf1, type = 'l', col = 'red')
P <- sum(!is.na(PitST_OOSNS)) #correct for both h = 1 and h = 4

lines(rvec, rvec - (kappa / sqrt(P)), col = 'black',lty=2)
lines(rvec, rvec + (kappa / sqrt(P)), col = 'black',lty=2)
lines(rvec, rvec , col = 'black',lty=2)

legend('bottomright', legend = c('GDP and NFCI', 'GDP only', 'Theoretical and 5% Critical Values'), cex = 0.5,fill = c('blue', 'red', 'black'))

#For h = 4, this PIT plot is different due to usage of a seed in CVfinalbootstrapInoue, even using the same as in Matlab, different results are obtained

