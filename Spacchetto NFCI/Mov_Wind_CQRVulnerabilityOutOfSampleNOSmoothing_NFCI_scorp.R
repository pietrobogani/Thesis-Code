
#implemento una moving window e vedo cosa viene

library(quantreg)
library(lubridate)
library(pracma)
library(readxl)
library(sn)
library(parallel)

# Clear workspace 
rm(list = ls())

# Load the functions
source("C:/Users/Pietro/Desktop/Pietro/Politecnico/Tesi/Thesis-Code/functions.R")



# Set forecast horizon (run script separately for h = 1 and h = 4)
h <- 4

loadsavedresults = FALSE; # If I just want to load results, set = TRUE


# Graphics settings
par(mfrow = c(1, 1))  # Reset plot window to single pane


# Load data 
file_path <- "Data_adj.xls"

# Read the file
data <- read_excel(file_path)
data<-data[,-c(3:10)]

# Filter data for 1973Q1-2015Q4
colnames(data)[1] <- "Time"
data$Time <- as.Date(data$Time)


# Subset the data
data <- data[data$Time >= as.Date("1973-01-01") & data$Time <= as.Date("2015-10-01"), ]
X <- data[,-1]
Time <- data$Time


# Set forecast settings
#QQ <- seq(0.05, 0.95, by = 0.05)
QQ <- seq(0.01, 0.99, by = 0.01) #Let's try a much more fine grid 
deltaYY <- 0.1
YY <- seq(-20, 20, by = deltaYY)
jtFirstOOS <- which(year(data$Time) == 1993 & month(data$Time) == 1)
indices <- which(QQ %in% c(0.05, 0.25, 0.5, 0.75, 0.95))
jq05 <- indices[1]
jq25 <- indices[2]
jq50 <- indices[3]
jq75 <- 75 #couldn't automatically translate from MATLAB, I set it manually
jq95 <- indices[4] #couldn't automatically translate from MATLAB, I set it manually

# Construct average growth rates
y <- X$A191RL1Q225SBEA
Yh <- matrix(0, nrow=length(y), ncol=4)


Yh <- stats::filter(y, rep(1/h, h), sides=1) #If h = 1, y = Yh
if (h>1){
  Yh[1:(h-1)] <- NA
}



#Construct matrices of regressors
Z <- cbind(1,X[,-1], y)
ZGDPonly <- cbind(1, y)
Z <- as.matrix(Z)

# Get length of Time and QQ/YY
len_time <- length(data$Time)
len_qq <- length(QQ)
len_yy <- length(YY)

# Initialize matrices to store forecasts
{
YQ_NaNs <- matrix(NA, len_time, len_qq)
YQ_low_ISC <- YQ_NaNs
YQ_high_ISC <- YQ_NaNs
YQ_ISC <- YQ_NaNs
YQ_low_OOSC <- YQ_NaNs
YQ_high_OOSC <- YQ_NaNs
YQ_OOSC <- YQ_NaNs
YQ_lowGDPonly_ISC <- YQ_NaNs
YQ_highGDPonly_ISC <- YQ_NaNs
YQGDPonly_ISC <- YQ_NaNs
YQGDPonly_OOSC <- YQ_NaNs
YQunc_ISC <- YQ_NaNs
YQunc_OOSC <- YQ_NaNs
YQunclow_ISC <- YQ_NaNs
YQunchigh_ISC <- YQ_NaNs
YQGDPonly_high_OOSC <- YQ_NaNs
YQGDPonly_low_OOSC <- YQ_NaNs
YQunclow_OOSC <- YQ_NaNs
YQunchigh_OOSC <- YQ_NaNs
YQunchigh_OOSC <- YQ_NaNs
YQunclow_OOSC <- YQ_NaNs

P_NaNs <- matrix(NA, len_time, len_yy)
PST_ISC <- P_NaNs
PST_OOSC <- P_NaNs
PSTGDPonly_ISC <- P_NaNs
PSTGDPonly_OOSC <- P_NaNs
PSTunc_ISC <- P_NaNs
PSTunc_OOSC <- P_NaNs

Q_NaNs <- matrix(NA, len_time, len_qq)
QST_ISC <- Q_NaNs
QST_OOSC <- Q_NaNs
QSTGDPonly_ISC <- Q_NaNs
QSTGDPonly_OOSC <- Q_NaNs
QSTunc_ISC <- Q_NaNs
QSTunc_OOSC <- Q_NaNs

C_NaNs <- matrix(NA, len_time, len_yy)
CST_ISC <- C_NaNs
CST_OOSC <- C_NaNs
CSTGDPonly_ISC <- C_NaNs
CSTGDPonly_OOSC <- C_NaNs
CSTunc_ISC <- C_NaNs
CSTunc_OOSC <- C_NaNs

STpar_NaNs <- matrix(NA, len_time, 4)
STpar_ISC <- STpar_NaNs
STpar_OOSC <- STpar_NaNs
STparGDPonly_ISC <- STpar_NaNs
STparGDPonly_OOSC <- STpar_NaNs
STparunc_ISC <- STpar_NaNs
STparunc_OOSC <- STpar_NaNs

Score_NaNs <- rep(NA, len_time)
ScoreST_ISC <- Score_NaNs
ScoreST_OOSC <- Score_NaNs
ScoreSTGDPonly_ISC <- Score_NaNs
ScoreSTGDPonly_OOSC <- Score_NaNs
ScoreSTunc_ISC <- Score_NaNs
ScoreSTunc_OOSC <- Score_NaNs

Pit_NaNs <- rep(NA, len_time)
PitST_ISC <- Pit_NaNs
PitST_OOSC <- Pit_NaNs
PitSTGDPonly_ISC <- Pit_NaNs
PitSTGDPonly_OOSC <- Pit_NaNs
PitSTunc_ISC <- Pit_NaNs
PitSTunc_OOSC <- Pit_NaNs

Entropy_NaNs <- rep(NA, len_time)
LeftEntropy_ISC <- Entropy_NaNs
LeftEntropy_OOSC <- Entropy_NaNs


#Split creating I1 and I2 for Conformal Prediction
full_length <- length(Yh[(h + 1):length(Yh)])
test_length <- full_length*50/100

permuted_indices <- c(1,2,3,4,sample((h+1):length(Yh))) #if you want to permute
#permuted_indices <- c(1:length(Yh)) # if you don't want to permute

Yh_perm <- Yh[permuted_indices]
Z_perm <- Z[permuted_indices,]
ZGDPonly_perm <- ZGDPonly[permuted_indices,]
Yh1 <- Yh_perm[(h+1):(h+test_length)]
Yh2 <- Yh_perm[(h+1+test_length):length(Yh)]
Z1 <- Z_perm[1:(test_length),]
Z2 <- Z_perm[(test_length+1):(length(Yh) - h),]
ZGDPonly1 <- ZGDPonly_perm[1:test_length,]
ZGDPonly2 <- ZGDPonly_perm[(test_length+1):(length(Yh) - h),]
}


if (loadsavedresults == FALSE) {
  
#-------------------    %% In-sample estimation of conditional QQ

Z1temp <- Z1[, apply(Z1, 2, function(x) var(x) > 1e-5)]  
Z2temp <- Z2[, apply(Z1, 2, function(x) var(x) > 1e-5)]  
Ztemp <- Z_perm[, apply(Z1, 2, function(x) var(x) > 1e-5)]  

for (jq in 1:length(QQ)) {
  
  #------ Conformalized Quantile regression with both NFCI and GDP
  
  YQ_low_ISC[(h + 1):(h + test_length), jq] <- -Inf 
  
  b_high <- rq(Yh1 ~ Z1temp, tau = QQ[jq])
  YQ_high_ISC[(h + 1):(h + full_length-test_length), jq] <- as.vector(cbind(1, Z2temp) %*% coef(b_high)) 

  # Initialize a vector for errors
  E_i <- rep(NA, length(Yh2))
  
  # Calculate errors for each point in the test set I2
  for (i in 1:length(E_i)) {
    E_i[i] <- max(YQ_low_ISC[h + i, jq] - Yh2[i], Yh2[i] - YQ_high_ISC[h + i, jq])
  }
  
  # Compute Q(QQ[jq])(E, I2) N.B 1 - alpha = QQ[jq]
  quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
  
  YQ_ISC[(h + 1):length(Yh), jq] <- as.vector(cbind(1,Ztemp[1:(length(Yh) - h),]) %*% coef(b_high)) + quantile_E
  
  
  
  #------ Conformalized Quantile regression with GDP only
  
  YQ_lowGDPonly_ISC[(h + 1):(h + test_length), jq] <- -Inf 
  
  b_highGDPonly <- rq(Yh1 ~ ZGDPonly1[,-1], tau= QQ[jq])
  YQ_highGDPonly_ISC[(h + 1):(h + full_length-test_length), jq] <- as.vector(ZGDPonly2 %*% coef(b_highGDPonly)) 

  # Initialize a vector for errors
  E_i <- rep(NA, length(Yh2))
  
  # Calculate errors for each point in the test set I2
  for (i in 1:length(E_i)) {
    E_i[i] <- max(YQ_lowGDPonly_ISC[h + i, jq] - Yh2[i], Yh2[i] - YQ_highGDPonly_ISC[h + i, jq])
  }
  
  # Compute Q(QQ[jq])(E, I2) N.B 1 - ?? = QQ[jq]
  quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
  
  YQGDPonly_ISC[(h + 1):length(Yh), jq] <- as.vector(ZGDPonly[1:(length(Yh) - h),] %*% coef(b_highGDPonly)) + quantile_E
  
  
  
  #------ Unconditional QQ (conformalized quantile regression on constant)
  
  YQunclow_ISC[(h + 1):(h + test_length), jq] <- - Inf 
  
  bunc_high <- rq(Yh1 ~ 1, tau=QQ[jq])
  YQunchigh_ISC[(h + 1):(h + test_length), jq] <- rep(coef(bunc_high), length((h + 1):(h + test_length)))

  # Initialize a vector for errors
  E_i <- rep(NA, length(Yh2))
  
  # Calculate errors for each point in the test set I2
  for (i in 1:length(E_i)) {
    E_i[i] <- max(YQunclow_ISC[h + i, jq] - Yh2[i], Yh2[i] - YQunchigh_ISC[h + i, jq])
  }
  
  # Compute Q(QQ[jq])(E, I2) N.B 1 - ?? = QQ[jq]
  quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
  
  YQunc_ISC[(h + 1):length(Yh), jq] <- rep(coef(bunc_high), length(Time) - h) + quantile_E
}


#---------    %% In-sample unconditional

{
  qqTarg <- YQunc_ISC[nrow(YQunc_ISC), ]

  # Assign values to matrices based on the skewed-t fit
  densities <- dst(YY, QQ, qqTarg) 
  replicated_matrix <- matrix(rep(densities, each = length(Time) - h), ncol = length(densities))
  PSTunc_ISC[(h + 1):nrow(PSTunc_ISC), ] <- replicated_matrix #Matrix containing for each point grid the associated unconditional density
  
  
  densities <- qst(QQ, qqTarg) 
  replicated_matrix <- matrix(rep(densities, each = length(Time) - h), ncol = length(densities))
  QSTunc_ISC[(h + 1):nrow(QSTunc_ISC), ] <- replicated_matrix #Matrix containing the quantile value for each level for the unconditional model
  
  
  densities <- pst(YY, QQ, qqTarg)
  replicated_matrix <- matrix(rep(densities, each = length(Time) - h), ncol = length(densities))
  CSTunc_ISC[(h + 1):nrow(CSTunc_ISC), ] <- replicated_matrix #Matrix containing for each point grid the associated uncondition cumulated density function
  
  
  ScoreSTunc_ISC[(h + 1):length(Yh)] <- dst(Yh[(h + 1):length(Yh)], QQ, qqTarg) #Matrix containing for each observation the associated unconditional density
  PitSTunc_ISC[(h + 1):length(Yh)] <- pst(Yh[(h + 1):length(Yh)], QQ, qqTarg) #Matrix containing for each observation the associated uncondition cumulated density function
   
}

#---------------------    %% Out-of-sample estimation of conditional QQ



for (jt in 1:(length(Time) - h)) { 
  
  
    month_val <- as.numeric(format(Time[jt], "%m"))
    year_val <- as.numeric(format(Time[jt], "%Y"))
    
    if (month_val == 1 && jt >= jtFirstOOS) { #jtFirstOOS is the date since when I start computing Out-of-sample estimations
      cat(sprintf("Computing in-sample and out-of-sample predictive densities in %d", year_val), "\n")
    } else {
      cat(sprintf("Computing in-sample predictive densities in %d", year_val), "\n")
    }
    
    YhRealized <- Yh[jt + h]
    
    qqTarg <- YQ_ISC[jt + h, ]

    PST_ISC[jt + h, ] <- dst(YY, QQ, qqTarg) 
    QST_ISC[jt + h, ] <- qst(QQ, qqTarg)
    CST_ISC[jt + h, ] <- pst(YY, QQ, qqTarg)
    ScoreST_ISC[jt + h ] <- dst(YhRealized, QQ, qqTarg)
    PitST_ISC[jt + h ] <- pst(YhRealized, QQ, qqTarg)    # is the probability to observe a value < of YhRealized in this distribution 
    
    # Calculate Downside Entropy
    Temp <- PST_ISC[jt + h, ] * (YY < QST_ISC[jt + h, jq50])
    
    non_zero_indexes <- (PSTunc_ISC[jt + h, ]!= 0) & (PST_ISC[jt + h, ] != 0)
    
    PSTunc_ISC_non_zero <- PSTunc_ISC[jt + h, ][non_zero_indexes]
    PST_ISC_non_zero <- PST_ISC[jt + h, ][non_zero_indexes]
    Temp_non_zero <- Temp[non_zero_indexes]
    
    LeftEntropy_ISC[jt + h] <- -sum((log(PSTunc_ISC_non_zero) - log(PST_ISC_non_zero)) * Temp_non_zero * deltaYY) 
    
    
    # Similar computations for GDP only
    qqTarg_GDPonly <- YQGDPonly_ISC[jt + h, ]

     
    PSTGDPonly_ISC[jt + h, ] <- dst(YY, QQ, qqTarg_GDPonly)
    QSTGDPonly_ISC[jt + h, ] <- qst(QQ, qqTarg_GDPonly)
    CSTGDPonly_ISC[jt + h, ] <- pst(YY, QQ, qqTarg_GDPonly)
    ScoreSTGDPonly_ISC[jt + h] <- dst(YhRealized, QQ, qqTarg_GDPonly)
    PitSTGDPonly_ISC[jt + h] <- pst(YhRealized, QQ, qqTarg_GDPonly) # is the probability to observe a value < of YhRealized in this distribution 
     
    
    
    if (jt >= jtFirstOOS) { #Now the Out-of-Sample part
      if (month(Time[jt]) == 1) {
        cat(sprintf("Now computing the real-time predictive densities in %d", year(Time[jt])), "\n")
      }
      
      window <- jtFirstOOS/3
      
      
      
      for (jq in 1:length(QQ)) {
        
        #------- Conformalized Quantile Regression with both NFCI and GDP, out-of-sample
        
        #Split creating I1 and I2
        full_length <- window
        test_length = round(full_length*50/100)
        Yh1 <- Yh[(jt-window+h+1):(h+test_length+jt-window)]
        Yh2 <- Yh[(h+1+test_length+jt-window):jt]
        Z1 <- Z[(jt-window+1):(test_length++jt-window),]
        Z2 <- Z[(test_length+jt-window+1):(jt - h),]
        ZGDPonly1 <- ZGDPonly[(jt-window+1):(jt-window+test_length),]
        ZGDPonly2 <- ZGDPonly[(test_length+jt-window+1):(jt - h),]

        Z1temp <- Z1[, apply(Z1, 2, function(x) var(x) > 1e-5)]  
        Z2temp <- Z2[, apply(Z1, 2, function(x) var(x) > 1e-5)]  
        Ztemp <- Z[, apply(Z1, 2, function(x) var(x) > 1e-5)] 
        
        
        #If some cols are too autocorrelated, I remove them
        ret <- remove_highly_correlated(Z1temp)
        
        Z1temp <- ret$cleaned_data
        col_to_remove <- ret$removed_indices
        
        if (!is.null(col_to_remove) && length(col_to_remove) > 0) {
          Z2temp <- Z2temp[,-col_to_remove]
          Ztemp <- Ztemp[,-col_to_remove]
        }
        
         #If ncols > nrows, I remove some cols
         ret <- remove_excess_columns(Z1temp)
         Z1temp <- ret$modified_matrix
         col_to_remove <- ret$removed_columns
         
         if (!is.null(col_to_remove) && length(col_to_remove) > 0) {
           Z2temp <- Z2temp[,-col_to_remove]
           Ztemp <- Ztemp[,-col_to_remove]
         }
         
         

        

        YQ_low_OOSC[(h + 1):(h + test_length), jq] <- -Inf 
        
        b_high <- rq(Yh1 ~ Z1temp, tau= QQ[jq]) #Train on I1
        YQ_high_OOSC[(h + 1):(h + length(Yh2)), jq] <- as.vector(cbind(1, Z2temp) %*% coef(b_high)) #Evaluate on I2

        # Initialize a vector for errors
        E_i <- rep(NA, length(Yh2))
        
        # Calculate errors for each point in the test set I2
        for (i in 1:length(E_i)) {
          E_i[i] <- max(YQ_low_OOSC[h + i, jq] - Yh2[i], Yh2[i] - YQ_high_OOSC[h + i, jq])
        }
        
        # Compute Q(1-alpha)(E, I2)
        quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
        
        YQ_OOSC[jt + h, jq] <- c(1, Ztemp[jt,]) %*% coef(b_high) + quantile_E 
        

        
        #------- Quantile regression with GDP only, out-of-sample
        
        YQGDPonly_low_OOSC[(h + 1):(h + test_length), jq] <- -Inf
        
        
        bGDPonly_high <- rq(Yh1 ~ ZGDPonly1[,-1], tau= QQ[jq]) #Train on I1
        YQGDPonly_high_OOSC[(h + 1):(h + length(Yh2)), jq] <- as.vector(ZGDPonly2 %*% coef(bGDPonly_high)) #Evaluate on I2
        # Initialize a vector for errors
        E_i <- rep(NA, length(Yh2))
        
        # Calculate errors for each point in the test set I2
        for (i in 1:length(E_i)) {
          E_i[i] <- max(YQGDPonly_low_OOSC[h + i, jq] - Yh2[i], Yh2[i] - YQGDPonly_high_OOSC[h + i, jq])
        }
        
        # Compute Q(1-alpha)(E, I2)
        quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
        
        # YQ_low_adj_OOSC[jt + h, jq] <- Z[jt,] %*% coef(b_low) - quantile_E 
        YQGDPonly_OOSC[jt + h, jq] <- ZGDPonly[jt,] %*% coef(bGDPonly_high) + quantile_E 
        

        
        
        #------- Quantile regression with Unconditional QQ, out-of-sample
        
        
        YQunclow_OOSC[(h + 1):(h + test_length), jq] <- - Inf
        
        bunc_high <- rq(Yh1 ~ 1, tau=QQ[jq])
        YQunchigh_OOSC[(h + 1):(h + test_length), jq] <- rep(coef(bunc_high), length((h + 1):(h + test_length)))

        # Initialize a vector for errors
        E_i <- rep(NA, length(Yh2))
        
        # Calculate errors for each point in the test set I2
        for (i in 1:length(E_i)) {
          E_i[i] <- max(YQunclow_OOSC[h + i, jq] - Yh2[i], Yh2[i] - YQunchigh_OOSC[h + i, jq])
        }
        
        # Compute Q(1-??)(E, I2)
        quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
        
        YQunc_OOSC[jt + h, jq] <- coef(bunc_high) + quantile_E
        
      }
      
      PST_OOSC[jt + h, ] <- dst(YY, QQ, YQ_OOSC[jt + h, ])
      QST_OOSC[jt + h, ] <- qst(QQ, YQ_OOSC[jt + h, ])
      CST_OOSC[jt + h, ] <- pst(YY, QQ, YQ_OOSC[jt + h, ])
      ScoreST_OOSC[jt + h] <- dst(YhRealized, QQ, YQ_OOSC[jt + h, ])
      PitST_OOSC[jt + h] <- pst(YhRealized, QQ, YQ_OOSC[jt + h, ]) # is the probability to observe a value < of YhRealized in this distribution 
      
      PSTGDPonly_OOSC[jt + h, ] <- dst(YY, QQ, YQGDPonly_OOSC[jt + h, ])
      QSTGDPonly_OOSC[jt + h, ] <- qst(QQ, YQGDPonly_OOSC[jt + h, ])
      CSTGDPonly_OOSC[jt + h, ] <- pst(YY, QQ, YQGDPonly_OOSC[jt + h, ])
      ScoreSTGDPonly_OOSC[jt + h] <- dst(YhRealized, QQ, YQGDPonly_OOSC[jt + h, ])
      PitSTGDPonly_OOSC[jt + h] <- pst(YhRealized, QQ, YQGDPonly_OOSC[jt + h, ]) # is the probability to observe a value < of YhRealized in this distribution 
       
      PSTunc_OOSC[jt + h, ] <- dst(YY, QQ, YQunc_OOSC[jt + h, ])
      QSTunc_OOSC[jt + h, ] <- qst(QQ, YQunc_OOSC[jt + h, ])
      CSTunc_OOSC[jt + h, ] <- pst(YY, QQ, YQunc_OOSC[jt + h, ])
      ScoreSTunc_OOSC[jt + h] <- dst(YhRealized, QQ, YQunc_OOSC[jt + h, ])
      PitSTunc_OOSC[jt + h] <- pst(YhRealized, QQ, YQunc_OOSC[jt + h, ]) # is the probability to observe a value < of YhRealized in this distribution 
       
      # Compute out-of-sample entropy for the full model 
      Temp <- PST_OOSC[jt + h, ] * (YY < QST_OOSC[jt + h, jq50])

      non_zero_indexes <- (PSTunc_OOSC[jt + h, ] != 0) & (PST_OOSC[jt + h, ] != 0)
      
      PSTunc_OOSC_non_zero <- PSTunc_OOSC[jt + h, ][non_zero_indexes]
      PST_OOSC_non_zero <- PST_OOSC[jt + h, ][non_zero_indexes]
      Temp_non_zero <- Temp[non_zero_indexes]
      
      LeftEntropy_OOSC[jt + h] <- -sum((log(PSTunc_OOSC_non_zero) - log(PST_OOSC_non_zero)) * Temp_non_zero * deltaYY)
    }
    
  } 
  
}
 
 
    filename <- paste("ResOOSCspacchettowindow_diviso_3_H", h, ".RData",sep="")
   cat(paste("Saving results to file", filename, "\n"))
   
   # Save all the variables to the .RData file
   save(
     YQ_ISC,      YQ_OOSC,      YQGDPonly_ISC,      YQGDPonly_OOSC,      YQunc_ISC,      YQunc_OOSC,
     PST_ISC,     PST_OOSC,     PSTGDPonly_ISC,     PSTGDPonly_OOSC,     PSTunc_ISC,     PSTunc_OOSC,
       QST_ISC,     QST_OOSC,     QSTGDPonly_ISC,     QSTGDPonly_OOSC,     QSTunc_ISC,     QSTunc_OOSC,
       CST_ISC,     CST_OOSC,     CSTGDPonly_ISC,     CSTGDPonly_OOSC,     CSTunc_ISC,     CSTunc_OOSC,
       STpar_ISC,   STpar_OOSC,   STparGDPonly_ISC,   STparGDPonly_OOSC,   STparunc_ISC,   STparunc_OOSC,
       ScoreST_ISC, ScoreST_OOSC, ScoreSTGDPonly_ISC, ScoreSTGDPonly_OOSC, ScoreSTunc_ISC, ScoreSTunc_OOSC,
       PitST_ISC,   PitST_OOSC,   PitSTGDPonly_ISC,   PitSTGDPonly_OOSC,   PitSTunc_ISC,   PitSTunc_OOSC,
       LeftEntropy_ISC, LeftEntropy_OOSC, 
       file=filename
     )
  #   
 # 
# 
# 
# #-------------------------------- per caricare dati salvati -----------------------
# 
# filename <- paste("ResOOS_H", h, "_50-50.RData", sep="")
# cat(paste("Loading results from file", filename, "\n"))
# 
# load(filename)
# 
# #-----------------------------------------------------------------------------------



PITtest_env <- new.env()
source("PITtest.r",local = PITtest_env)

rstestboot_env <- new.env()
source("rstestboot.r",local = rstestboot_env)







# Figure 10. Out-of-sample Predictions.             

# (a)/(b) QQ
par(mar = c(3, 3, 2, 1))  # Adjust the values as needed (bottom, left, top, right)

plot(Time, YQ_OOSC[, jq05], type = 'l', col = 'blue', xlab = 'Time', ylab = 'QQ', xlim = range(Time),ylim = c(-20,20))
lines(Time, YQ_OOSC[, jq50], type = 'l', col = 'blue', lty = 2)
lines(Time, YQ_OOSC[,jq95], type = 'l', col = 'blue', lty = 3) 
lines(Time, YQ_ISC[, jq05], type = 'l', col = 'black', lty = 1)
lines(Time, YQ_ISC[, jq50], type = 'l', col = 'black', lty = 2)
lines(Time, YQ_ISC[, jq95], type = 'l', col = 'black', lty = 3)





# (c)/(d) Downside Entropy        
plot(Time, LeftEntropy_OOSC, type = 'l', col = 'blue', 
     xlab = 'Time', ylab = 'Entropy', xlim = range(Time))
lines(Time, LeftEntropy_ISC, type = 'l', col = 'black', lty = 2)



# Figure 11. Out-of-sample Accuracy.   
# (a)/(b) Predictive scores
plot(Time, ScoreST_OOSC, type = 'l', col = 'blue', xlab = 'Time', ylab = 'Scores')
lines(Time, ScoreSTGDPonly_OOSC, type = 'l', col = 'black', lty = 2)
legend('topleft', legend = c('GDP and NFCI', 'GDP only'))

# h = 4:> mean(ScoreST_OOSC - ScoreST_OOSCpaper, na.rm = TRUE) == 0.004654713. Predictive scores of my model are better. 
# h = 4:> sum(ScoreST_OOSC - ScoreST_OOSCpaper, na.rm = TRUE) == 0.4096147. Confirmed by using sum instead of mean
# h = 4:> mean(ScoreSTGDPonly_OOSC - ScoreSTGDPonly_OOSC1, na.rm = TRUE) == 0.04962592. Also the model with only GDP performs better
# h = 4:> sum(ScoreSTGDPonly_OOSC - ScoreSTGDPonly_OOSC1, na.rm = TRUE) == 4.367081. Confirmed by using sum instead of mean

# h = 1:> mean(ScoreST_OOSC - ScoreST_OOSC1, na.rm = TRUE) == 0.01211243 Predictive scores of my model are better. 
# h = 1:> sum(ScoreST_OOSC - ScoreST_OOSC1, na.rm = TRUE) == 1.102231 Confirmed by using sum instead of mean
# h = 1:> mean(ScoreSTGDPonly_OOSC - ScoreSTGDPonly_OOSC1, na.rm = TRUE) == 0.02495498 Also the model with only GDP performs better
# h = 1:> sum(ScoreSTGDPonly_OOSC - ScoreSTGDPonly_OOSC1, na.rm = TRUE) #== 2.270903 Confirmed by using sum instead of mean
plot(ecdf(ScoreSTGDPonly_OOSC), main="PS ECDF Comparison GDPonly", col="blue", lty=1, lwd=2)
lines(ecdf(ScoreSTGDPonly_OOSC1), col="red", lty=2, lwd=2)
legend("bottomright", legend=c("Mio", "Paper"), col=c("blue", "red"), lty=c(1, 2), lwd=2)





# (c)/(d): PITs
# The code below was modified from files provided by Barbara Rossi and
# Tatevik Sekhposyan implementing the specification tests for predictive
# densities described in Rossi and Sekhposyan (2017).
rvec <- seq(0.001, 1, by = 0.001)
zST_ecdf <- PITtest_env$PITtest(PitST_OOSC, rvec)
CnSS_model <- 1 - mean((zST_ecdf - seq(0, 1, length.out = length(zST_ecdf)))^2) / var(zST_ecdf) # h = 4: 0.67701012121 || h = 1: 0.9366  is the value. 1 is perfect calibrated
mean_squared_diff <- mean((zST_ecdf-rvec)^2) # h = 4: 0.02338473 || h = 1: 0.005109203

zSTGDPonly_ecdf <- PITtest_env$PITtest(PitSTGDPonly_OOSC, rvec)
CnSS_model_GDPonly <- 1 - mean((zSTGDPonly_ecdf - seq(0, 1, length.out = length(zSTGDPonly_ecdf)))^2) / var(zSTGDPonly_ecdf) # h = 4: 0.872747225 || h = 1: 0.95697 is the value. 1 is perfect calibrated
mean_squared_diff_GDPonly <- mean((zSTGDPonly_ecdf-rvec)^2) # h = 4: 0.009966178 || h = 1: 0.003439986

if (h == 1) {
  # Use asymptotic 5% critical value from Rossi and Sekhposyan (2017): 1.34
  kappa <- 1.34
  kappaGDPonly <- 1.34
  
} else if (h == 4) {
  # Compute bootstrapped 5% critical values
  PITs <- cbind(PitST_OOSC, PitSTGDPonly_OOSC)
  PITs <- PITs[(jtFirstOOS + h):nrow(PITs), , drop = FALSE]
  
  #testcritvalues <- matrix(NA, nrow = 1, ncol = 2, dimnames = list(NULL, c('GDP and NFCI', 'GDP only')))
  testcritvalues <- array(NA, dim = c(2, 3, 2))
  
  for (i in 1:2) {
    testcritvalues[,, i] <- round(rstestboot_env$rstestboot(PITs[, i])$critvalues[2] * 100) / 100
  }
  
  kappa <- testcritvalues[1, 2, 1] #different from Matlab due to seed in CVfinalbootstrapInoue
  kappaGDPonly <- testcritvalues[1, 2, 2] #different from Matlab due to seed in CVfinalbootstrapInoue
}

# Plot PIT for full quantile regression vs. quantile regression with GDP only
plot(rvec, zST_ecdf, type = 'l', col = 'blue', xlab = '??', ylab = 'Empirical CDF')
lines(rvec, zSTGDPonly_ecdf, type = 'l', col = 'red')
P <- sum(!is.na(PitST_OOSC)) #correct for both h = 1 and h = 4

lines(rvec, rvec - (kappa / sqrt(P)), col = 'black',lty=2)
lines(rvec, rvec + (kappa / sqrt(P)), col = 'black',lty=2)
lines(rvec,rvec , col = 'black',lty=2)

legend('bottomright', legend = c('GDP and NFCI', 'GDP only', 'Theoretical and 5% Critical Values'), cex = 0.5,fill = c('blue', 'red', 'black'))

#For h = 4, this PIT plot is different due to usage of a seed in CVfinalbootstrapInoue, even using the same as in Matlab, different results are obtained

