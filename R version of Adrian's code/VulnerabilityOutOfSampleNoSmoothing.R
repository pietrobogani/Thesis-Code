# Install and load necessary packages
library(quantreg)
library(lubridate)
library(pracma)
library(readxl)
library(sn)
library(quantreg)



# Clear workspace 
rm(list = ls())


#IMPLEMENTATION OF QST, DST, PST, THAT I NEED SINCE I DON'T DO SMOOTHING ANYMORE

pst <- function(X, QQ, qqtarg) { #I consider it a step a function
  
  sapply(X, function(x) {
    if (length(qqtarg[qqtarg <= x]) == 0) {
      return(0) # If x is less than the smallest quantile value, the cumulative probability is 0
    }
    
    if (x > max(qqtarg, na.rm = TRUE)) {
      return(1) # If x is greater than all qqtarg, return the maximum cumulative probability
    }
    
    max_value_not_exceeding_x <- max(qqtarg[qqtarg <= x], na.rm = TRUE)
    quantile_index <- which(qqtarg == max_value_not_exceeding_x)
    
    
    return(QQ[min(quantile_index)])
  })
}

# 
# dst <- function(X, QQ, qqTarg) { #I consider in between quantiles probabilities is uniformly distributed
#   
#   # Function to find density for a single point
#   find_density <- function(x) {
#     density <- 0
#     for (i in 1:(length(qqTarg) - 1)) {
# 
#         if (x == qqTarg[i] && x == qqTarg[i+1]) {# Handle zero-length interval by using adjacent intervals. s
#       
#           if(i > 1 && i < length(qqTarg) - 1) #central values of the quantiles
#              density <- 1 / (qqTarg[i + 2] - qqTarg[i - 1]) * (QQ[i + 2] - QQ[i - 1])
#           else if (i == 1)
#              density <- 1 / (qqTarg[i + 2] - qqTarg[i]) * (QQ[i + 2] - QQ[i]) #Otherwise I'm out of index!
#           else if (i == length(qqTarg) - 1)
#             density <- 1 / (qqTarg[i + 1] - qqTarg[i - 1]) * (QQ[i + 1] - QQ[i - 1]) #Otherwise I'm out of index!
#           
#         return(density)
#       }
#       
#       else if (x >= qqTarg[i] && x < qqTarg[i + 1]) {
#         
#         if (abs(qqTarg[i] - qqTarg[i + 1]) < 0.02) { #with such a small interval, this create lots of problems giving high values in output
#           
#           if(i > 1 && i < length(qqTarg) - 1) #central values of the quantiles
#             density <- 1 / (qqTarg[i + 2] - qqTarg[i - 1]) * (QQ[i + 2] - QQ[i - 1])
#           else if (i == 1)
#             density <- 1 / (qqTarg[i + 2] - qqTarg[i]) * (QQ[i + 2] - QQ[i]) #Otherwise I'm out of index!
#           else if (i == length(qqTarg) - 1)
#             density <- 1 / (qqTarg[i + 1] - qqTarg[i - 1]) * (QQ[i + 1] - QQ[i - 1]) #Otherwise I'm out of index!
# 
#         }
#         
#         else density <- 1 / (qqTarg[i + 1] - qqTarg[i]) * (QQ[i + 1] - QQ[i])
#         
#         if (density > 1){
#           cat("Interval:", qqTarg[i], "-", qqTarg[i + 1], "Density:", density, "\n") #Just to check if I get insanely high values
#         }
#         return(density)
#       }
#       
#     }
#     # If x is outside the range of given QQ, return 0 as the density
#     return(0)
#   }
#   
#   # Apply find_density to each element in X
#   densities <- sapply(X, find_density)
#   
#   return(densities)
# }






dst <- function(X, QQ, qqTarg) {
  # Function to find density for a single point
  find_density <- function(x) {
    density <- 0
    for (i in 1:(length(qqTarg) - 1)) {
      
      # Function to dynamically find an interval that is not too small
      find_wider_interval <- function(index) {
        left_index <- index
        right_index <- index + 1
        while (abs(qqTarg[right_index] - qqTarg[left_index]) < 0.01) {
          if (left_index > 1) {
            left_index <- left_index - 1
          }
          if (right_index < length(qqTarg)) {
            right_index <- right_index + 1
          }
          
        }

        return(c(left_index, right_index))
      }
      
      if (x == qqTarg[i] && x == qqTarg[i + 1]) {
        indices <- find_wider_interval(i)
        density <- 1 / (qqTarg[indices[2]] - qqTarg[indices[1]]) * (QQ[indices[2]] - QQ[indices[1]])
        return(density)
      } 
      else if (x >= qqTarg[i] && x < qqTarg[i + 1]) {
        if (abs(qqTarg[i] - qqTarg[i + 1]) < 0.01) {
          indices <- find_wider_interval(i)
          density <- 1 / (qqTarg[indices[2]] - qqTarg[indices[1]]) * (QQ[indices[2]] - QQ[indices[1]])
        } 
        else {
          density <- 1 / (qqTarg[i + 1] - qqTarg[i]) * (QQ[i + 1] - QQ[i])
        }
        
        if (density > 1) {
          cat("Interval:", qqTarg[i], "-", qqTarg[i + 1], "Density:", density, "\n") # Just to check if I get insanely high values
        }
        return(density)
      }
      
    }
    # If x is outside the range of given QQ, return 0 as the density
    return(0)
  }
  
  # Apply find_density to each element in X
  densities <- sapply(X, find_density)
  
  return(densities)
}












qst <- function(QQ, qqTarg) { # qst is always called giving in input QQ. Without smoothing, the estimated quantiles are exactly qqTarg!
  if (length(QQ)== length(qqTarg)) {
    return(qqTarg)
  }
  else
    cat("wrong dimensions")
}







# Set forecast horizon (run script separately for h = 1 and h = 4)
h <- 4




loadsavedresults = FALSE; # If I run code already and results are stored in ResOOS_H



# Graphics settings - R's graphics system differs from MATLAB's, so some modifications are necessary
par(mfrow = c(1, 1))  # Reset plot window to single pane



# Load data 
file_path <- "DataVulnerabilityAppendix.xls"

# Read the file
data <- read_excel(file_path)
data<-data[,1:3]

# Filter data for 1973Q1-2015Q4
colnames(data)[1] <- "Time"
data$Time <- as.Date(data$Time)


# Subset the data
data <- data[data$Time >= as.Date("1973-01-01") & data$Time <= as.Date("2015-10-01"), ]
X <- data[,2:3]
Time <- data$Time


# Set forecast settings
#QQ <- seq(0.05, 0.95, by = 0.05)
QQ <- seq(0.01, 0.99, by = 0.01) #Let's try a much more fine grid 
#QQ <- c(0.01, QQ, 0.99)
deltaYY <- 0.1
YY <- seq(-20, 20, by = deltaYY)
jtFirstOOS <- which(year(data$Time) == 1993 & month(data$Time) == 1)
indices <- which(QQ %in% c(0.05, 0.25, 0.5, 0.75, 0.95))
jq05 <- indices[1]
jq25 <- indices[2]
jq50 <- indices[3]
jq75 <- 16 #couldn't automatically translate from MATLAB, I set it manually, no idea why
jq95 <- indices[4]

# Construct average growth rates
y <- X$A191RL1Q225SBEA
Yh <- matrix(0, nrow=length(y), ncol=4)


Yh <- filter(y, rep(1/h, h), sides=1) #If h = 1, y = Yh
if (h>1){
  Yh[1:(h-1)] <- NA
}
              
hist(y)

#Construct matrices of regressors
Z <- cbind(1, X[,2], y)
ZGDPonly <- cbind(1, y)
Z <-as.matrix(Z)

#if (loadsavedresults == FALSE) {

#----------------------- In-sample and out-of-sample estimation/forecasting

{
# Get length of Time and QQ/YY
len_time <- length(data$Time)
len_qq <- length(QQ)
len_yy <- length(YY)

# Initialize matrices to store forecasts

# Raw quantiles
YQ_NaNs <- matrix(NA, len_time, len_qq)
YQ_IS <- YQ_NaNs
YQ_OOS <- YQ_NaNs
YQGDPonly_IS <- YQ_NaNs
YQGDPonly_OOS <- YQ_NaNs
YQunc_IS <- YQ_NaNs
YQunc_OOS <- YQ_NaNs

# PDFs (evaluated over grid)
P_NaNs <- matrix(NA, len_time, len_yy)
PST_IS <- P_NaNs
PST_OOS <- P_NaNs
PSTGDPonly_IS <- P_NaNs
PSTGDPonly_OOS <- P_NaNs
PSTunc_IS <- P_NaNs
PSTunc_OOS <- P_NaNs

# Smoothed quantiles
Q_NaNs <- matrix(NA, len_time, len_qq)
QST_IS <- Q_NaNs
QST_OOS <- Q_NaNs
QSTGDPonly_IS <- Q_NaNs
QSTGDPonly_OOS <- Q_NaNs
QSTunc_IS <- Q_NaNs
QSTunc_OOS <- Q_NaNs

# CDFs (evaluated over grid)
C_NaNs <- matrix(NA, len_time, len_yy)
CST_IS <- C_NaNs
CST_OOS <- C_NaNs
CSTGDPonly_IS <- C_NaNs
CSTGDPonly_OOS <- C_NaNs
CSTunc_IS <- C_NaNs
CSTunc_OOS <- C_NaNs

# Skewed t-distribution parameters
STpar_NaNs <- matrix(NA, len_time, 4)
STpar_IS <- STpar_NaNs
STpar_OOS <- STpar_NaNs
STparGDPonly_IS <- STpar_NaNs
STparGDPonly_OOS <- STpar_NaNs
STparunc_IS <- STpar_NaNs
STparunc_OOS <- STpar_NaNs

# Predictive scores
Score_NaNs <- rep(NA, len_time)
ScoreST_IS <- Score_NaNs
ScoreST_OOS <- Score_NaNs
ScoreSTGDPonly_IS <- Score_NaNs
ScoreSTGDPonly_OOS <- Score_NaNs
ScoreSTunc_IS <- Score_NaNs
ScoreSTunc_OOS <- Score_NaNs

# Probability integral transforms
Pit_NaNs <- rep(NA, len_time)
PitST_IS <- Pit_NaNs
PitST_OOS <- Pit_NaNs
PitSTGDPonly_IS <- Pit_NaNs
PitSTGDPonly_OOS <- Pit_NaNs
PitSTunc_IS <- Pit_NaNs
PitSTunc_OOS <- Pit_NaNs

# Left entropy
Entropy_NaNs <- rep(NA, len_time)
LeftEntropy_IS <- Entropy_NaNs
LeftEntropy_OOS <- Entropy_NaNs

}



#-------------------    %% In-sample estimation of conditional quantiles

{
# In-sample estimation of conditional quantiles

for (jq in 1:length(QQ)) {
  # Quantile regression with both NFCI and GDP
  b <- rq(Yh[(h + 1):length(Yh)] ~ Z[1:(length(Yh) - h),-1], tau=QQ[jq])
  YQ_IS[(h + 1):length(Yh), jq] <- as.vector(Z[1:(length(Yh) - h),] %*% coef(b)) #I train the model on ((h + 1):length(Yh))-points and I store 
  #the estimation of the quantiles for each of this point. Every column represent a different quantile
  
  # Quantile regression with GDP only
  bGDPonly <- rq(Yh[(h + 1):length(Yh)] ~ ZGDPonly[1:(length(Yh) - h),-1], tau=QQ[jq])
  YQGDPonly_IS[(h + 1):length(Yh), jq] <- as.vector(ZGDPonly[1:(length(Yh) - h),] %*% coef(bGDPonly))
  
  # Unconditional quantiles (quantile regression on constant)
  bunc <- rq(Yh[(h + 1):length(Yh)] ~ 1, tau=QQ[jq])
  YQunc_IS[(h + 1):length(Yh), jq] <- rep(coef(bunc), length(Time) - h)
}
  
}


#---------    %% Fit skewed-t distribution for in-sample unconditional quantiles
{

  qqTarg <- YQunc_IS[nrow(YQunc_IS), ]
  
  
  # Assign values to matrices based on the skewed-t fit
  densities <- dst(YY, QQ, qqTarg) # PROBLEMA! visto che ho solo quantili empirici, sotto quantile 0.05 e sopra 0.95 assegno densità =0. Cosa che con smoothing non succede. Come risolvere?
  plot(YY,densities) #forma assomiglia a quella originale, un po' skewed a destra
  replicated_matrix <- matrix(rep(densities, each = length(Time) - h), ncol = length(densities))
  PSTunc_IS[(h + 1):nrow(PSTunc_IS), ] <- replicated_matrix #Giusto, ma tanti 0, forse troppi che danno problemi
  
  
  densities <- qst(QQ, qqTarg) #diverso dall'originale che invece dava i quantili dopo smoothing
  plot(QQ,densities) #anche questo simile
  replicated_matrix <- matrix(rep(densities, each = length(Time) - h), ncol = length(densities))
  QSTunc_IS[(h + 1):nrow(QSTunc_IS), ] <- replicated_matrix #Credo giusto
  
  
  densities <- pst(YY, QQ, qqTarg)
  plot(YY, densities) #molto molto simile all'originale
  replicated_matrix <- matrix(rep(densities, each = length(Time) - h), ncol = length(densities))
  CSTunc_IS[(h + 1):nrow(CSTunc_IS), ] <- replicated_matrix #giusto, ma pochi valori xk step function 
  
  
  #STparunc_IS[(h + 1):nrow(STparunc_IS), ] <- matrix(rep(c(lc, sc, sh, df), times = length(Time) - h), 
  #                                                   nrow = length(Time) - h, 
  #                                                   byrow = TRUE)
  #Questo semplicemente salva i parametri, non mi serve più
  
  
  ScoreSTunc_IS[(h + 1):length(Yh)] <- dst(Yh[(h + 1):length(Yh)], QQ, qqTarg) #corretto
  plot(Yh[(h + 1):length(Yh)],ScoreSTunc_IS[(h + 1):length(Yh)])
  PitSTunc_IS[(h + 1):length(Yh)] <- pst(Yh[(h + 1):length(Yh)], QQ, qqTarg)
}

#---------------------    %% Fit t-densities for in-sample and out-of-sample estimation
{

for (jt in 1:(length(Time) - h)) {
  
  month_val <- as.numeric(format(Time[jt], "%m"))
  year_val <- as.numeric(format(Time[jt], "%Y"))
  
  if (month_val == 1 && jt >= jtFirstOOS) {
    cat(sprintf("Computing in-sample and out-of-sample predictive densities in %d", year_val), "\n")
  } else {
    cat(sprintf("Computing in-sample predictive densities in %d", year_val), "\n")
  }
  
  YhRealized <- Yh[jt + h]
  
  qqTarg <- YQ_IS[jt + h, ]

  PST_IS[jt + h, ] <- dst(YY, QQ, qqTarg) 
  QST_IS[jt + h, ] <- qst(QQ, qqTarg)
  CST_IS[jt + h, ] <- pst(YY, QQ, qqTarg)
  #STpar_IS[jt + h, ] <- c(lc, sc, sh, df)
  ScoreST_IS[jt + h ] <- dst(YhRealized, QQ, qqTarg)
  PitST_IS[jt + h ] <- pst(YhRealized, QQ, qqTarg)   #pressochè identico all'originale 
  
  Temp <- PST_IS[jt + h, ] * (YY < QST_IS[jt + h, jq50])
  
  non_zero_indexes <- (PSTunc_IS[jt + h, ]!= 0) & (PST_IS[jt + h, ] != 0)
  
  # Create new vectors with values from those indexes
  PSTunc_IS_non_zero <- PSTunc_IS[jt + h, ][non_zero_indexes]
  PST_IS_non_zero <- PST_IS[jt + h, ][non_zero_indexes]
  Temp_non_zero <- Temp[non_zero_indexes]
  
  LeftEntropy_IS[jt + h] <- -sum((log(PSTunc_IS_non_zero) - log(PST_IS_non_zero)) * Temp_non_zero * deltaYY) 
  
  
  
  # Similar computations for GDP only
  qqTarg_GDPonly <- YQGDPonly_IS[jt + h, ]

  
  PSTGDPonly_IS[jt + h, ] <- dst(YY, QQ, qqTarg_GDPonly)
  QSTGDPonly_IS[jt + h, ] <- qst(QQ, qqTarg_GDPonly)
  CSTGDPonly_IS[jt + h, ] <- pst(YY, QQ, qqTarg_GDPonly)
  #STparGDPonly_IS[jt + h, ] <- c(lc, sc, sh, df)
  ScoreSTGDPonly_IS[jt + h] <- dst(YhRealized, QQ, qqTarg_GDPonly)
  PitSTGDPonly_IS[jt + h] <- pst(YhRealized, QQ, qqTarg_GDPonly) # is the probability to observe a value < of YhRealized in this distribution 
  
  

  
  if (jt >= jtFirstOOS) {
    if (month(Time[jt]) == 1) {
      cat(sprintf("Now computing the real-time predictive densities in %d", year(Time[jt])), "\n")
    }
    
    for (jq in 1:length(QQ)) {                                       
      # Quantile regression with both NFCI and GDP, out-of-sample
      b <- rq(Yh[(h + 1):jt] ~ Z[1:(jt - h),-1], QQ[jq])
      YQ_OOS[jt + h, jq] <- Z[jt, ] %*% coef(b)
      
      
      # b <- rq(Yh[(h + 1):length(Yh)] ~ Z[1:(length(Yh) - h),-1], tau=QQ[jq]) this is in sample, for comparison
      # YQ_IS[(h + 1):length(Yh), jq] <- as.vector(Z[1:(length(Yh) - h),] %*% coef(b))
      # 
      
      
      
      # Quantile regression with GDP only, out-of-sample
      bGDPonly <- rq(Yh[(h + 1):jt] ~ ZGDPonly[1:(jt- h),-1], tau=QQ[jq])
      YQGDPonly_OOS[jt + h, jq] <- ZGDPonly[jt, ] %*% coef(bGDPonly)
      # Unconditional quantiles, out-of-sample
      bunc <- rq(Yh[(h + 1):jt ] ~ 1, QQ[jq])
      YQunc_OOS[jt + h, jq] <- coef(bunc)
      #YQunc_IS[(h + 1):length(Yh), jq] <- rep(coef(bunc), length(Time) - h)
    }
    #params <- QQInterpolation_env$QQInterpolation(YQ_OOS[jt + h, ], QQ) #YQ_OOS[jt + h, ] is the new qqTarg!
    PST_OOS[jt + h, ] <- dst(YY, QQ, YQ_OOS[jt + h, ])
    QST_OOS[jt + h, ] <- qst(QQ, YQ_OOS[jt + h, ])
    CST_OOS[jt + h, ] <- pst(YY, QQ, YQ_OOS[jt + h, ])
    #STpar_OOS[jt + h, ] <- c(params$lc, params$sc, params$sh, params$df)
    ScoreST_OOS[jt + h] <- dst(YhRealized, QQ, YQ_OOS[jt + h, ])
    PitST_OOS[jt + h] <- pst(YhRealized, QQ, YQ_OOS[jt + h, ]) # is the probability to observe a value < of YhRealized in this distribution 
    
    #params_GDPonly <- QQInterpolation_env$QQInterpolation(YQGDPonly_OOS[jt + h, ], QQ)
    PSTGDPonly_OOS[jt + h, ] <- dst(YY, QQ, YQGDPonly_OOS[jt + h, ])
    QSTGDPonly_OOS[jt + h, ] <- qst(QQ, YQGDPonly_OOS[jt + h, ])
    CSTGDPonly_OOS[jt + h, ] <- pst(YY, QQ, YQGDPonly_OOS[jt + h, ])
    #STparGDPonly_OOS[jt + h, ] <- c(params_GDPonly$lc, params_GDPonly$sc, params_GDPonly$sh, params_GDPonly$df)
    ScoreSTGDPonly_OOS[jt + h] <- dst(YhRealized, QQ, YQGDPonly_OOS[jt + h, ])
    PitSTGDPonly_OOS[jt + h] <- pst(YhRealized, QQ, YQGDPonly_OOS[jt + h, ]) # is the probability to observe a value < of YhRealized in this distribution 
    
    #params_unc <- QQInterpolation_env$QQInterpolation(YQunc_OOS[jt + h, ], QQ)
    PSTunc_OOS[jt + h, ] <- dst(YY, QQ, YQunc_OOS[jt + h, ])
    QSTunc_OOS[jt + h, ] <- qst(QQ, YQunc_OOS[jt + h, ])
    CSTunc_OOS[jt + h, ] <- pst(YY, QQ, YQunc_OOS[jt + h, ])
    #STparunc_OOS[jt + h, ] <- c(params_unc$lc, params_unc$sc, params_unc$sh, params_unc$df)
    ScoreSTunc_OOS[jt + h] <- dst(YhRealized, QQ, YQunc_OOS[jt + h, ])
    PitSTunc_OOS[jt + h] <- pst(YhRealized, QQ, YQunc_OOS[jt + h, ]) # is the probability to observe a value < of YhRealized in this distribution 
    
    # Compute entropy for skewed t-distribution from quantile regression with GDP and NFCI, out-of-sample
    Temp <- PST_OOS[jt + h, ] * (YY < QST_OOS[jt + h, jq50])
    
    non_zero_indexes <- (PSTunc_OOS[jt + h, ] != 0) & (PST_OOS[jt + h, ] != 0)
    
    # Create new vectors with values from those indexes
    PSTunc_OOS_non_zero <- PSTunc_OOS[jt + h, ][non_zero_indexes]
    PST_OOS_non_zero <- PST_OOS[jt + h, ][non_zero_indexes]
    Temp_non_zero <- Temp[non_zero_indexes]
    
    LeftEntropy_OOS[jt + h] <- -sum((log(PSTunc_OOS_non_zero) - log(PST_OOS_non_zero)) * Temp_non_zero * deltaYY)
    }
  
} 

}
  
  
# filename <- paste("ResOOS_H", h, ".RData", sep="")
# cat(paste("Saving results to file", filename, "\n"))
# 
# # Save all the variables to the .RData file
# save(
#   YQ_IS,      YQ_OOS,      YQGDPonly_IS,      YQGDPonly_OOS,      YQunc_IS,      YQunc_OOS,
#   PST_IS,     PST_OOS,     PSTGDPonly_IS,     PSTGDPonly_OOS,     PSTunc_IS,     PSTunc_OOS,
#   QST_IS,     QST_OOS,     QSTGDPonly_IS,     QSTGDPonly_OOS,     QSTunc_IS,     QSTunc_OOS,
#   CST_IS,     CST_OOS,     CSTGDPonly_IS,     CSTGDPonly_OOS,     CSTunc_IS,     CSTunc_OOS,
#   STpar_IS,   STpar_OOS,   STparGDPonly_IS,   STparGDPonly_OOS,   STparunc_IS,   STparunc_OOS,
#   ScoreST_IS, ScoreST_OOS, ScoreSTGDPonly_IS, ScoreSTGDPonly_OOS, ScoreSTunc_IS, ScoreSTunc_OOS,
#   PitST_IS,   PitST_OOS,   PitSTGDPonly_IS,   PitSTGDPonly_OOS,   PitSTunc_IS,   PitSTunc_OOS,
#   LeftEntropy_IS, LeftEntropy_OOS, 
#   file=filename
# )
# 
# rm(filename)  # equivalent to MATLAB's clear('filename')
# 
# 
# }
# 
# filename <- paste("ResOOS_H", h, ".RData", sep="")
# cat(paste("Loading results from file", filename, "\n"))
# 
# load(filename)

#------------------------------

PITtest_env <- new.env()
source("PITtest.r",local = PITtest_env)

rstestboot_env <- new.env()
source("rstestboot.r",local = rstestboot_env)







# Figure 10. Out-of-sample Predictions.             #CORRETTO anche dopo parallelizione di QuantInterp!!!!!!!!
 
# (a)/(b) Quantiles
par(mar = c(3, 3, 2, 1))  # Adjust the values as needed (bottom, left, top, right)

plot(Time, YQ_OOS[, jq05], type = 'l', col = 'blue', xlab = 'Time', ylab = 'Quantiles', xlim = range(Time),ylim = c(-20,20))
lines(Time, YQ_OOS[, jq50], type = 'l', col = 'blue', lty = 2)
lines(Time, YQ_OOS[,jq95], type = 'l', col = 'blue', lty = 3) 
lines(Time, YQ_IS[, jq05], type = 'l', col = 'black', lty = 1)
lines(Time, YQ_IS[, jq50], type = 'l', col = 'black', lty = 2)
lines(Time, YQ_IS[, jq95], type = 'l', col = 'black', lty = 3)





# (c)/(d) Downside Entropy        #Ora che ho messo parallelizzazione dentro QuantInterp, LeftEntropy_OOS è leggermente diversa, ma poco
plot(Time, LeftEntropy_OOS, type = 'l', col = 'blue', 
     xlab = 'Time', ylab = 'Entropy', xlim = range(Time))
lines(Time, LeftEntropy_IS, type = 'l', col = 'black', lty = 2)



# Figure 11. Out-of-sample Accuracy.   #CORRETTO anche dopo parallelizione di QuantInterp!!!!!!!!!!!!!
# (a)/(b) Predictive scores
plot(Time, ScoreST_OOS, type = 'l', col = 'blue', xlab = 'Time', ylab = 'Scores')
lines(Time, ScoreSTGDPonly_OOS, type = 'l', col = 'black', lty = 2)
legend('topleft', legend = c('GDP and NFCI', 'GDP only'))



# (c)/(d): PITs #CORRETTO anche dopo parallelizione di QuantInterp!!!!!!!!!!!!!
# The code below was modified from files provided by Barbara Rossi and
# Tatevik Sekhposyan implementing the specification tests for predictive
# densities described in Rossi and Sekhposyan (2017).
rvec <- seq(0, 1, by = 0.001)
zST_ecdf1 <- PITtest_env$PITtest(PitST_OOS, rvec)
CnSS_model <- 1 - mean((zST_ecdf1 - seq(0, 1, length.out = length(zST_ecdf1)))^2) / var(zST_ecdf1) # h = 4: 0.55658995 || h = 1: 0.7951442  is the value. 1 is perfect calibrated
mean_squared_diff <- mean((zST_ecdf1-rvec)^2) # h = 4: 0.03382078 || h = 1: 0.01705973


zSTGDPonly_ecdf1 <- PITtest_env$PITtest(PitSTGDPonly_OOS, rvec)
CnSS_model_GDPonly <- 1 - mean((zSTGDPonly_ecdf1 - seq(0, 1, length.out = length(zSTGDPonly_ecdf1)))^2) / var(zSTGDPonly_ecdf1) # h = 4: 0.92477 || h = 1:  0.9237593 is the value. 1 is perfect calibrated
mean_squared_diff_GDPonly <- mean((zSTGDPonly_ecdf1-rvec)^2) # h = 4: 0.008269042 || h = 1: 0.008313394


if (h == 1) {
  # Use asymptotic 5% critical value from Rossi and Sekhposyan (2017): 1.34
  kappa <- 1.34
  kappaGDPonly <- 1.34
  
} else if (h == 4) {
  # Compute bootstrapped 5% critical values
  PITs <- cbind(PitST_OOS, PitSTGDPonly_OOS)
  PITs <- PITs[(jtFirstOOS + h):nrow(PITs), , drop = FALSE]
  
  #testcritvalues <- matrix(NA, nrow = 1, ncol = 2, dimnames = list(NULL, c('GDP and NFCI', 'GDP only')))
  testcritvalues <- array(NA, dim = c(2, 3, 2))
  
  for (i in 1:2) {
    testcritvalues[,, i] <- round(rstestboot_env$rstestboot(PITs[, i])$critvalues[2] * 100) / 100
  }
  
  kappa <- testcritvalues[1, 2, 1] #different from Matlab due to seed in CVfinalbootstrapInoue
  kappaGDPonly <- testcritvalues[1, 2, 2] #different from Matlab due to seed in CVfinalbootstrapInoue
}

# Plot PIT for full quantile regression vs. quantile regression with GDP only
plot(rvec, zST_ecdf1, type = 'l', col = 'blue', xlab = 'tau', ylab = 'Empirical CDF')
lines(rvec, zSTGDPonly_ecdf1, type = 'l', col = 'red')
P <- sum(!is.na(PitST_OOS)) #correct for both h = 1 and h = 4

lines(rvec, rvec - (kappa / sqrt(P)), col = 'black',lty=2)
lines(rvec, rvec + (kappa / sqrt(P)), col = 'black',lty=2)
lines(rvec, rvec , col = 'black',lty=2)

legend('bottomright', legend = c('GDP and NFCI', 'GDP only', 'Theoretical and 5% Critical Values'), cex = 0.5,fill = c('blue', 'red', 'black'))

#For h = 4, this PIT plot is different due to usage of a seed in CVfinalbootstrapInoue, even using the same as in Matlab, different results are obtained
