QST_OOS <- Q_NaNs
QSTGDPonly_IS <- Q_NaNs
QSTGDPonly_OOS <- Q_NaNs
QSTunc_IS <- Q_NaNs
QSTunc_OOS <- Q_NaNs
# CDFs (evaluated over grid)
C_NaNs <- matrix(NA, len_time, len_yy)
CST_IS <- C_NaNs
CST_OOS <- C_NaNs
CSTGDPonly_IS <- C_NaNs
CSTGDPonly_OOS <- C_NaNs
CSTunc_IS <- C_NaNs
CSTunc_OOS <- C_NaNs
# Skewed t-distribution parameters
STpar_NaNs <- matrix(NA, len_time, 4)
STpar_IS <- STpar_NaNs
STpar_OOS <- STpar_NaNs
STparGDPonly_IS <- STpar_NaNs
STparGDPonly_OOS <- STpar_NaNs
STparunc_IS <- STpar_NaNs
STparunc_OOS <- STpar_NaNs
# Predictive scores
Score_NaNs <- rep(NA, len_time)
ScoreST_IS <- Score_NaNs
ScoreST_OOS <- Score_NaNs
ScoreSTGDPonly_IS <- Score_NaNs
ScoreSTGDPonly_OOS <- Score_NaNs
ScoreSTunc_IS <- Score_NaNs
ScoreSTunc_OOS <- Score_NaNs
# Probability integral transforms
Pit_NaNs <- rep(NA, len_time)
PitST_IS <- Pit_NaNs
PitST_OOS <- Pit_NaNs
PitSTGDPonly_IS <- Pit_NaNs
PitSTGDPonly_OOS <- Pit_NaNs
PitSTunc_IS <- Pit_NaNs
PitSTunc_OOS <- Pit_NaNs
# Left entropy
Entropy_NaNs <- rep(NA, len_time)
LeftEntropy_IS <- Entropy_NaNs
LeftEntropy_OOS <- Entropy_NaNs
}
#-------------------    %% In-sample estimation of conditional quantiles
{
# In-sample estimation of conditional quantiles
for (jq in 1:length(QQ)) {
# Quantile regression with both NFCI and GDP
b <- rq(Yh[(h + 1):length(Yh)] ~ Z[1:(length(Yh) - h),-1], tau=QQ[jq])
YQ_IS[(h + 1):length(Yh), jq] <- as.vector(Z[1:(length(Yh) - h),] %*% coef(b)) #I train the model on ((h + 1):length(Yh))-points and I store
#the estimation of the quantiles for each of this point. Every column represent a different quantile
# Quantile regression with GDP only
bGDPonly <- rq(Yh[(h + 1):length(Yh)] ~ ZGDPonly[1:(length(Yh) - h),-1], tau=QQ[jq])
YQGDPonly_IS[(h + 1):length(Yh), jq] <- as.vector(ZGDPonly[1:(length(Yh) - h),] %*% coef(bGDPonly))
# Unconditional quantiles (quantile regression on constant)
bunc <- rq(Yh[(h + 1):length(Yh)] ~ 1, tau=QQ[jq])
YQunc_IS[(h + 1):length(Yh), jq] <- rep(coef(bunc), length(Time) - h)
}
}
qqTarg <- YQunc_IS[nrow(YQunc_IS), ]
# Assign values to matrices based on the skewed-t fit
densities <- dst(YY, QQ, qqTarg) # PROBLEMA! visto che ho solo quantili empirici, sotto quantile 0.05 e sopra 0.95 assegno densità =0. Cosa che con smoothing non succede. Come risolvere?
plot(YY,densities) #forma assomiglia a quella originale, un po' skewed a destra
replicated_matrix <- matrix(rep(densities, each = length(Time) - h), ncol = length(densities))
PSTunc_IS[(h + 1):nrow(PSTunc_IS), ] <- replicated_matrix #Giusto, ma tanti 0, forse troppi che danno problemi
densities <- qst(QQ, qqTarg) #diverso dall'originale che invece dava i quantili dopo smoothing
plot(QQ,densities) #anche questo simile
replicated_matrix <- matrix(rep(densities, each = length(Time) - h), ncol = length(densities))
QSTunc_IS[(h + 1):nrow(QSTunc_IS), ] <- replicated_matrix #Credo giusto
densities <- pst(YY, QQ, qqTarg)
plot(YY, densities) #molto molto simile all'originale
replicated_matrix <- matrix(rep(densities, each = length(Time) - h), ncol = length(densities))
CSTunc_IS[(h + 1):nrow(CSTunc_IS), ] <- replicated_matrix #giusto, ma pochi valori xk step function
ScoreSTunc_IS[(h + 1):length(Yh)] <- dst(Yh[(h + 1):length(Yh)], QQ, qqTarg) #corretto
plot(Yh[(h + 1):length(Yh)],ScoreSTunc_IS[(h + 1):length(Yh)])
PitSTunc_IS[(h + 1):length(Yh)] <- pst(Yh[(h + 1):length(Yh)], QQ, qqTarg)
#---------    %% Fit skewed-t distribution for in-sample unconditional quantiles
{
qqTarg <- YQunc_IS[nrow(YQunc_IS), ]
# Assign values to matrices based on the skewed-t fit
densities <- dst(YY, QQ, qqTarg) # PROBLEMA! visto che ho solo quantili empirici, sotto quantile 0.05 e sopra 0.95 assegno densità =0. Cosa che con smoothing non succede. Come risolvere?
plot(YY,densities) #forma assomiglia a quella originale, un po' skewed a destra
replicated_matrix <- matrix(rep(densities, each = length(Time) - h), ncol = length(densities))
PSTunc_IS[(h + 1):nrow(PSTunc_IS), ] <- replicated_matrix #Giusto, ma tanti 0, forse troppi che danno problemi
densities <- qst(QQ, qqTarg) #diverso dall'originale che invece dava i quantili dopo smoothing
plot(QQ,densities) #anche questo simile
replicated_matrix <- matrix(rep(densities, each = length(Time) - h), ncol = length(densities))
QSTunc_IS[(h + 1):nrow(QSTunc_IS), ] <- replicated_matrix #Credo giusto
densities <- pst(YY, QQ, qqTarg)
plot(YY, densities) #molto molto simile all'originale
replicated_matrix <- matrix(rep(densities, each = length(Time) - h), ncol = length(densities))
CSTunc_IS[(h + 1):nrow(CSTunc_IS), ] <- replicated_matrix #giusto, ma pochi valori xk step function
#STparunc_IS[(h + 1):nrow(STparunc_IS), ] <- matrix(rep(c(lc, sc, sh, df), times = length(Time) - h),
#                                                   nrow = length(Time) - h,
#                                                   byrow = TRUE)
#Questo semplicemente salva i parametri, non mi serve più
ScoreSTunc_IS[(h + 1):length(Yh)] <- dst(Yh[(h + 1):length(Yh)], QQ, qqTarg) #corretto
plot(Yh[(h + 1):length(Yh)],ScoreSTunc_IS[(h + 1):length(Yh)])
PitSTunc_IS[(h + 1):length(Yh)] <- pst(Yh[(h + 1):length(Yh)], QQ, qqTarg)
}
#---------------------    %% Fit t-densities for in-sample and out-of-sample estimation
{
for (jt in 1:(length(Time) - h)) {
month_val <- as.numeric(format(Time[jt], "%m"))
year_val <- as.numeric(format(Time[jt], "%Y"))
if (month_val == 1 && jt >= jtFirstOOS) {
cat(sprintf("Computing in-sample and out-of-sample predictive densities in %d", year_val), "\n")
} else {
cat(sprintf("Computing in-sample predictive densities in %d", year_val), "\n")
}
YhRealized <- Yh[jt + h]
qqTarg <- YQ_IS[jt + h, ]
PST_IS[jt + h, ] <- dst(YY, QQ, qqTarg)
QST_IS[jt + h, ] <- qst(QQ, qqTarg)
CST_IS[jt + h, ] <- pst(YY, QQ, qqTarg)
#STpar_IS[jt + h, ] <- c(lc, sc, sh, df)
ScoreST_IS[jt + h ] <- dst(YhRealized, QQ, qqTarg)
PitST_IS[jt + h ] <- pst(YhRealized, QQ, qqTarg)   #pressochè identico all'originale
Temp <- PST_IS[jt + h, ] * (YY < QST_IS[jt + h, jq50])
non_zero_indexes <- (PSTunc_IS[jt + h, ]!= 0) & (PST_IS[jt + h, ] != 0)
# Create new vectors with values from those indexes
PSTunc_IS_non_zero <- PSTunc_IS[jt + h, ][non_zero_indexes]
PST_IS_non_zero <- PST_IS[jt + h, ][non_zero_indexes]
Temp_non_zero <- Temp[non_zero_indexes]
LeftEntropy_IS[jt + h] <- -sum((log(PSTunc_IS_non_zero) - log(PST_IS_non_zero)) * Temp_non_zero * deltaYY)
# Similar computations for GDP only
qqTarg_GDPonly <- YQGDPonly_IS[jt + h, ]
PSTGDPonly_IS[jt + h, ] <- dst(YY, QQ, qqTarg_GDPonly)
QSTGDPonly_IS[jt + h, ] <- qst(QQ, qqTarg_GDPonly)
CSTGDPonly_IS[jt + h, ] <- pst(YY, QQ, qqTarg_GDPonly)
#STparGDPonly_IS[jt + h, ] <- c(lc, sc, sh, df)
ScoreSTGDPonly_IS[jt + h] <- dst(YhRealized, QQ, qqTarg_GDPonly)
PitSTGDPonly_IS[jt + h] <- pst(YhRealized, QQ, qqTarg_GDPonly) # is the probability to observe a value < of YhRealized in this distribution
if (jt >= jtFirstOOS) {
if (month(Time[jt]) == 1) {
cat(sprintf("Now computing the real-time predictive densities in %d", year(Time[jt])), "\n")
}
for (jq in 1:length(QQ)) {
# Quantile regression with both NFCI and GDP, out-of-sample
b <- rq(Yh[(h + 1):jt] ~ Z[1:(jt - h),-1], QQ[jq])
YQ_OOS[jt + h, jq] <- Z[jt, ] %*% coef(b)
# b <- rq(Yh[(h + 1):length(Yh)] ~ Z[1:(length(Yh) - h),-1], tau=QQ[jq]) this is in sample, for comparison
# YQ_IS[(h + 1):length(Yh), jq] <- as.vector(Z[1:(length(Yh) - h),] %*% coef(b))
#
# Quantile regression with GDP only, out-of-sample
bGDPonly <- rq(Yh[(h + 1):jt] ~ ZGDPonly[1:(jt- h),-1], tau=QQ[jq])
YQGDPonly_OOS[jt + h, jq] <- ZGDPonly[jt, ] %*% coef(bGDPonly)
# Unconditional quantiles, out-of-sample
bunc <- rq(Yh[(h + 1):jt ] ~ 1, QQ[jq])
YQunc_OOS[jt + h, jq] <- coef(bunc)
#YQunc_IS[(h + 1):length(Yh), jq] <- rep(coef(bunc), length(Time) - h)
}
#params <- QQInterpolation_env$QQInterpolation(YQ_OOS[jt + h, ], QQ) #YQ_OOS[jt + h, ] is the new qqTarg!
PST_OOS[jt + h, ] <- dst(YY, QQ, YQ_OOS[jt + h, ])
QST_OOS[jt + h, ] <- qst(QQ, YQ_OOS[jt + h, ])
CST_OOS[jt + h, ] <- pst(YY, QQ, YQ_OOS[jt + h, ])
#STpar_OOS[jt + h, ] <- c(params$lc, params$sc, params$sh, params$df)
ScoreST_OOS[jt + h] <- dst(YhRealized, QQ, YQ_OOS[jt + h, ])
PitST_OOS[jt + h] <- pst(YhRealized, QQ, YQ_OOS[jt + h, ]) # is the probability to observe a value < of YhRealized in this distribution
#params_GDPonly <- QQInterpolation_env$QQInterpolation(YQGDPonly_OOS[jt + h, ], QQ)
PSTGDPonly_OOS[jt + h, ] <- dst(YY, QQ, YQGDPonly_OOS[jt + h, ])
QSTGDPonly_OOS[jt + h, ] <- qst(QQ, YQGDPonly_OOS[jt + h, ])
CSTGDPonly_OOS[jt + h, ] <- pst(YY, QQ, YQGDPonly_OOS[jt + h, ])
#STparGDPonly_OOS[jt + h, ] <- c(params_GDPonly$lc, params_GDPonly$sc, params_GDPonly$sh, params_GDPonly$df)
ScoreSTGDPonly_OOS[jt + h] <- dst(YhRealized, QQ, YQGDPonly_OOS[jt + h, ])
PitSTGDPonly_OOS[jt + h] <- pst(YhRealized, QQ, YQGDPonly_OOS[jt + h, ]) # is the probability to observe a value < of YhRealized in this distribution
#params_unc <- QQInterpolation_env$QQInterpolation(YQunc_OOS[jt + h, ], QQ)
PSTunc_OOS[jt + h, ] <- dst(YY, QQ, YQunc_OOS[jt + h, ])
QSTunc_OOS[jt + h, ] <- qst(QQ, YQunc_OOS[jt + h, ])
CSTunc_OOS[jt + h, ] <- pst(YY, QQ, YQunc_OOS[jt + h, ])
#STparunc_OOS[jt + h, ] <- c(params_unc$lc, params_unc$sc, params_unc$sh, params_unc$df)
ScoreSTunc_OOS[jt + h] <- dst(YhRealized, QQ, YQunc_OOS[jt + h, ])
PitSTunc_OOS[jt + h] <- pst(YhRealized, QQ, YQunc_OOS[jt + h, ]) # is the probability to observe a value < of YhRealized in this distribution
# Compute entropy for skewed t-distribution from quantile regression with GDP and NFCI, out-of-sample
Temp <- PST_OOS[jt + h, ] * (YY < QST_OOS[jt + h, jq50])
non_zero_indexes <- (PSTunc_OOS[jt + h, ] != 0) & (PST_OOS[jt + h, ] != 0)
# Create new vectors with values from those indexes
PSTunc_OOS_non_zero <- PSTunc_OOS[jt + h, ][non_zero_indexes]
PST_OOS_non_zero <- PST_OOS[jt + h, ][non_zero_indexes]
Temp_non_zero <- Temp[non_zero_indexes]
LeftEntropy_OOS[jt + h] <- -sum((log(PSTunc_OOS_non_zero) - log(PST_OOS_non_zero)) * Temp_non_zero * deltaYY)
}
}
}
PITtest_env <- new.env()
source("PITtest.r",local = PITtest_env)
rstestboot_env <- new.env()
PITtest_env <- new.env()
source("PITtest.r",local = PITtest_env)
rstestboot_env <- new.env()
source("rstestboot.r",local = rstestboot_env)
# Figure 10. Out-of-sample Predictions.             #CORRETTO anche dopo parallelizione di QuantInterp!!!!!!!!
# (a)/(b) Quantiles
par(mar = c(3, 3, 2, 1))  # Adjust the values as needed (bottom, left, top, right)
plot(Time, YQ_OOS[, jq05], type = 'l', col = 'blue', xlab = 'Time', ylab = 'Quantiles', xlim = range(Time),ylim = c(-20,20))
lines(Time, YQ_OOS[, jq50], type = 'l', col = 'blue', lty = 2)
lines(Time, YQ_OOS[,jq95], type = 'l', col = 'blue', lty = 3)
lines(Time, YQ_IS[, jq05], type = 'l', col = 'black', lty = 1)
lines(Time, YQ_IS[, jq50], type = 'l', col = 'black', lty = 2)
lines(Time, YQ_IS[, jq95], type = 'l', col = 'black', lty = 3)
# (c)/(d) Downside Entropy        #Ora che ho messo parallelizzazione dentro QuantInterp, LeftEntropy_OOS è leggermente diversa, ma poco
plot(Time, LeftEntropy_OOS, type = 'l', col = 'blue',
xlab = 'Time', ylab = 'Entropy', xlim = range(Time))
lines(Time, LeftEntropy_IS, type = 'l', col = 'black', lty = 2)
# Figure 11. Out-of-sample Accuracy.   #CORRETTO anche dopo parallelizione di QuantInterp!!!!!!!!!!!!!
# (a)/(b) Predictive scores
plot(Time, ScoreST_OOS, type = 'l', col = 'blue', xlab = 'Time', ylab = 'Scores')
lines(Time, ScoreSTGDPonly_OOS, type = 'l', col = 'black', lty = 2)
legend('topleft', legend = c('GDP and NFCI', 'GDP only'))
# (c)/(d): PITs #CORRETTO anche dopo parallelizione di QuantInterp!!!!!!!!!!!!!
# The code below was modified from files provided by Barbara Rossi and
# Tatevik Sekhposyan implementing the specification tests for predictive
# densities described in Rossi and Sekhposyan (2017).
rvec <- seq(0, 1, by = 0.001)
zST_ecdf1 <- PITtest_env$PITtest(PitST_OOS, rvec)
CnSS_model <- 1 - mean((zST_ecdf1 - seq(0, 1, length.out = length(zST_ecdf1)))^2) / var(zST_ecdf1) # h = 4: 0.55658995 || h = 1: 0.7951442  is the value. 1 is perfect calibrated
mean_squared_diff <- mean((zST_ecdf1-rvec)^2) # h = 4: 0.03382078 || h = 1: 0.01705973
zSTGDPonly_ecdf1 <- PITtest_env$PITtest(PitSTGDPonly_OOS, rvec)
CnSS_model_GDPonly <- 1 - mean((zSTGDPonly_ecdf1 - seq(0, 1, length.out = length(zSTGDPonly_ecdf1)))^2) / var(zSTGDPonly_ecdf1) # h = 4: 0.92477 || h = 1:  0.9237593 is the value. 1 is perfect calibrated
mean_squared_diff_GDPonly <- mean((zSTGDPonly_ecdf1-rvec)^2) # h = 4: 0.008269042 || h = 1: 0.008313394
if (h == 1) {
# Use asymptotic 5% critical value from Rossi and Sekhposyan (2017): 1.34
kappa <- 1.34
kappaGDPonly <- 1.34
} else if (h == 4) {
# Compute bootstrapped 5% critical values
PITs <- cbind(PitST_OOS, PitSTGDPonly_OOS)
PITs <- PITs[(jtFirstOOS + h):nrow(PITs), , drop = FALSE]
#testcritvalues <- matrix(NA, nrow = 1, ncol = 2, dimnames = list(NULL, c('GDP and NFCI', 'GDP only')))
testcritvalues <- array(NA, dim = c(2, 3, 2))
for (i in 1:2) {
testcritvalues[,, i] <- round(rstestboot_env$rstestboot(PITs[, i])$critvalues[2] * 100) / 100
}
kappa <- testcritvalues[1, 2, 1] #different from Matlab due to seed in CVfinalbootstrapInoue
kappaGDPonly <- testcritvalues[1, 2, 2] #different from Matlab due to seed in CVfinalbootstrapInoue
}
# Plot PIT for full quantile regression vs. quantile regression with GDP only
plot(rvec, zST_ecdf1, type = 'l', col = 'blue', xlab = 'tau', ylab = 'Empirical CDF')
lines(rvec, zSTGDPonly_ecdf1, type = 'l', col = 'red')
P <- sum(!is.na(PitST_OOS)) #correct for both h = 1 and h = 4
lines(rvec, rvec - (kappa / sqrt(P)), col = 'black',lty=2)
lines(rvec, rvec + (kappa / sqrt(P)), col = 'black',lty=2)
lines(rvec, rvec , col = 'black',lty=2)
legend('bottomright', legend = c('GDP and NFCI', 'GDP only', 'Theoretical and 5% Critical Values'), cex = 0.5,fill = c('blue', 'red', 'black'))
#For h = 4, this PIT plot is different due to usage of a seed in CVfinalbootstrapInoue, even using the same as in Matlab, different results are obtained
tau <- 1
#--- MODEL IN THE PAPER
# y(t) = GDP % increase in the quarter t
# Yh(t) = 1/4 * (y(t) + y(t-1) + y(t-2) + y(t-3))
# Z(t) <- cbind(1, NFCI(t), y(t))
# Quantile Regression: Yh(t) ~ Z(t-4) = c(NFCI(t-4),y(t-4))
#--- DATA GENERATING PROCESS
# Yh(t) = tau/4 * (y(t) + y(t-1) + y(t-2) + y(t-3)) + noise
# y(t)  ~ ...
# NFCI(t) ~ ...
# noise  ~ Skewed-t(mean, sd, skewness,kurtosis)
#------ PARAMETERS OF THE MODEL TO BE SET
tau <- 1
m <- 2.75
var <- 3
mean <- 0
sd <- 2
skewness <- 1 #skewness of skew-t.
gamma2 <- 30 #kurtosis of skew-t. It's range influences the possible values of skewness
h <- 4 # Other choice is h = 1
library(caret)
library(sn)
library(quantreg)
#--- MODEL IN THE PAPER
# y(t) = GDP % increase in the quarter t
# Yh(t) = 1/4 * (y(t) + y(t-1) + y(t-2) + y(t-3))
# Z(t) <- cbind(1, NFCI(t), y(t))
# Quantile Regression: Yh(t) ~ Z(t-4) = c(NFCI(t-4),y(t-4))
#--- DATA GENERATING PROCESS
# Yh(t) = tau/4 * (y(t) + y(t-1) + y(t-2) + y(t-3)) + noise
# y(t)  ~ ...
# NFCI(t) ~ ...
# noise  ~ Skewed-t(mean, sd, skewness,kurtosis)
#------ PARAMETERS OF THE MODEL TO BE SET
tau <- 1
m <- 2.75
var <- 3
mean <- 0
sd <- 2
skewness <- 1 #skewness of skew-t.
gamma2 <- 30 #kurtosis of skew-t. It's range influences the possible values of skewness
h <- 4 # Other choice is h = 1
library(caret)
library(sn)
library(quantreg)
#GENERATE DATA
y <-  rnorm(1004, mean = m, sd = var) # simulate GDP growth quarter by quarter
Yh <- filter(y, rep(1/h, h), sides=1) * tau # moving average of the h past values
beta <- runif(1, min = 0, max = 2)
alpha <- log(beta)
skew_prop <- c(mean=mean, sd=sd, gamma1=alpha,gamma2 = 1000) #alpha >0 => left-skewed
skew_params  <- cp2dp(skew_prop, family="ST")
noise <- rsn(1004, dp=skew_params1)
#GENERATE DATA
y <-  rnorm(1004, mean = m, sd = var) # simulate GDP growth quarter by quarter
Yh <- filter(y, rep(1/h, h), sides=1) * tau # moving average of the h past values
beta <- runif(1, min = 0, max = 2)
alpha <- log(beta)
skew_prop <- c(mean=mean, sd=sd, gamma1=alpha,gamma2 = 1000) #alpha >0 => left-skewed
skew_params  <- cp2dp(skew_prop, family="ST")
noise <- rsn(1004, dp=skew_params)
#Yh <- Yh + noise
hist(noise)
hist(Yh)
Z <- cbind(1, y)
Z <- as.matrix(Z)
#CREATE TEST AND TRAINING SET  ------> Non ha senso, faccio già in-sample e out-of-sample
# set.seed(123) # Setting a seed for reproducibility
# trainIndex <- createDataPartition(Yh, p = 0.8, list = FALSE) #80% train, 20% test
# Yh_train <- Yh[trainIndex]
# Yh_test <- Yh[-trainIndex]
# Z_train <- Z[trainIndex,]
# Z_test <- Z[-trainIndex,]
#QUANTILE REGRESSION (CORRETTA, UGUALE AL PAPER ORIGINALE)
QQ <- seq(0.05, 0.95, by = 0.05) #vector of quantiles I'll do quantile regression on
jtFirstOOS <- 500 #First index for out-of-sample computations
Quant_IS <- matrix(NA, nrow(Z), length(QQ))
Quantunc_IS <- matrix(NA, nrow(Z), length(QQ))
Quant_OOS <- matrix(NA, nrow(Z), length(QQ))
Quantunc_OOS <- matrix(NA, nrow(Z), length(QQ))
#IN SAMPLE
for (jq in 1:length(QQ)) {
#CONDITIONAL
QR <- rq(Yh[(h+1):length(Yh)] ~ Z[1:(length(Yh) - h),-1], tau=QQ[jq])
Quant_IS[(h+1):length(Yh), jq] <- as.vector(Z[1:(length(Yh) - h),] %*% coef(QR))
#UNCONDITIONAL
suppressWarnings(QRunc <- rq(Yh[(h+1):length(Yh)] ~ 1, tau=QQ[jq]))
Quantunc_IS[(h+1):length(Yh), jq] <- rep(coef(QRunc), nrow(Z) - h) #columns has to be equal
}
#OUT OF SAMPLE
for (jt in jtFirstOOS:(length(Yh)-h)) {
for (jq in 1:length(QQ)) {
#CONDITIONAL
QR <- rq(Yh[(h+1):jt] ~ Z[1:(jt - h),-1], tau=QQ[jq])
Quant_OOS[jt + h, jq] <- Z[jt, ] %*% coef(QR)
#UNCONDITIONAL
suppressWarnings(QRunc <- rq(Yh[(h+1) : jt] ~ 1, QQ[jq]))
Quantunc_OOS[jt + h, jq] <- coef(QRunc)
}
}
# CONFORMALIZED QUANTILE REGRESSION
#CREATE TEST AND CALIBRATION SETS FOR CQR WITH A 50-50 SPLIT
length <- length(Yh[(h+1):length(Yh)])
Z1 <- Z[1:(length/2),]
Z2 <- Z[(length/2+1):(length(Yh)-h),]
Yh1 <- Yh[(h+1):(length/2+h)]
Yh2 <- Yh[(length/2+h+1):length(Yh)]
CQuant_IS <- matrix(NA, nrow(Z), length(QQ))
CQuantunc_IS <- matrix(NA, nrow(Z), length(QQ))
Q_low <- matrix(NA, nrow(Z), length(QQ))
Q_high <- matrix(NA, nrow(Z), length(QQ))
#IN SAMPLE
for (jq in 1:length(QQ)) {
#CONDITIONAL
Q_low[(h+1):(h + length(Yh1)), jq] <- -Inf
QR <- rq(Yh1 ~ Z1[,-1], tau= QQ[jq])
Q_high[(h+1):(h+length(Yh2)), jq] <- as.vector(Z2 %*% coef(QR))
# Initialize a vector for errors
E_i <- rep(NA, length(Yh2))
# Calculate errors for each point in the test set I2
for (i in 1:length(E_i)) {
E_i[i] <- max(Q_low[h+i, jq] - Yh2[i], Yh2[i] - Q_high[h+i, jq])
}
# Compute Q(QQ[jq])(E, I2) N.B 1 - ?? = QQ[jq]
quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
CQuant_IS[(h+1):length(Yh) ,jq] <- as.vector(Z[1:(length(Yh) - h),] %*% coef(QR)) + quantile_E
#UNCONDITIONAL
Q_low[(h+1):(h + length(Yh1)), jq] <- -Inf
suppressWarnings(QRunc <- rq(Yh1 ~ 1, tau= QQ[jq]))
Q_high[(h+1):(h+length(Yh2)), jq] <- rep(coef(QRunc), length((h+1):(h + length(Yh2))))
# Initialize a vector for errors
E_i <- rep(NA, length(Yh2))
# Calculate errors for each point in the test set I2
for (i in 1:length(E_i)) {
E_i[i] <- max(Q_low[h+i, jq] - Yh2[i], Yh2[i] - Q_high[h+i, jq])
}
# Compute Q(QQ[jq])(E, I2) N.B 1 - ?? = QQ[jq]
quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
CQuantunc_IS[(h+1):length(Yh) ,jq] <- rep(coef(QRunc), length(Yh) - h) + quantile_E
}
#OUT OF SAMPLE
CQuant_OOS <- matrix(NA, nrow(Z), length(QQ))
CQuantunc_OOS <- matrix(NA, nrow(Z), length(QQ))
for (jt in jtFirstOOS:(length(Yh)-h)) {
full_length <- length(Yh[(h+1):jt])
test_length = full_length*50/100
Yh1 <- Yh[(h+1):(h+test_length)]
Yh2 <- Yh[(test_length+h+1):jt] #Yh1 and Yh2 correctly have same dimension
Z1 <- Z[1:test_length,]
Z2 <- Z[(test_length+1):(jt-h),] #Z1 and Z2 correctly have same dimension
for (jq in 1:length(QQ)) {
#CONDITIONAL
Q_low[(h+1):(h+length(Yh1)), jq] <- -Inf
QR <- rq(Yh1 ~ Z1[,-1], tau= QQ[jq])
Q_high[(h+1):(h+length(Yh2)), jq] <- as.vector(Z2 %*% coef(QR))
# Initialize a vector for errors
E_i <- rep(NA, length(Yh2))
# Calculate errors for each point in the test set I2
for (i in 1:length(E_i)) {
E_i[i] <- max(Q_low[h+i, jq] - Yh2[i], Yh2[i] - Q_high[h+i, jq])
}
# Compute Q(QQ[jq])(E, I2) N.B 1 - ?? = QQ[jq]
quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
CQuant_OOS[jt+h,jq] <- Z[jt,] %*% coef(QR) + quantile_E
#UNCONDITIONAL
Q_low[(h+1):(h+length(Yh1)), jq] <- -Inf
suppressWarnings(QRunc <- rq(Yh1 ~ 1, tau= QQ[jq]))
Q_high[(h+1):(h+length(Yh2)), jq] <- rep(coef(QRunc), length((h+1):(h + test_length)))
# Initialize a vector for errors
E_i <- rep(NA, length(Yh2))
# Calculate errors for each point in the test set I2
for (i in 1:length(E_i)) {
E_i[i] <- max(Q_low[h+i, jq] - Yh2[i], Yh2[i] - Q_high[h+i, jq])
}
# Compute Q(QQ[jq])(E, I2) N.B 1 - ?? = QQ[jq]
quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
CQuantunc_OOS[jt+h ,jq] <- coef(QRunc) + quantile_E
}
}
#CALIBRATION OF QUANTILE REGRESSION
# This function returns the cumulative probability for a given value X
cumulative_prob <- function(X, quantiles, values) {
if (length(values[values <= X]) == 0) {
return(0) # If X is less than the smallest value, the cumulative probability is 0
}
max_value_not_exceeding_X <- max(values[values <= X], na.rm = TRUE)
quantile_index <- which(values == max_value_not_exceeding_X)
if (length(quantile_index) == 0) {
return(1) # If X is greater than all values, return the maximum cumulative probability
}
return(quantiles[min(quantile_index)])
}
PitST_IS <- rep(NA, length(Yh))
PitSTunc_IS <- rep(NA, length(Yh))
PitST_OOS <- rep(NA, length(Yh))
PitSTunc_OOS <- rep(NA, length(Yh))
#IN SAMPLE, UNCONDITIONAL
qqTarg <- Quantunc_IS[nrow(Quantunc_IS), ]
for(i in (h+1):length(Yh)) {
PitSTunc_IS[i] <- cumulative_prob(Yh[i], QQ,qqTarg)
}
#IN SAMPLE, CONDITIONAL
for (jt in 1:(length(Yh) - h)) {
YhRealized <- Yh[jt + h]
qqTarg <- Quant_IS[jt + h, ]
PitST_IS[jt + h] <- cumulative_prob(YhRealized, QQ, qqTarg)
}
#OUT OF SAMPLE, CONDITIONAL
for (jt in jtFirstOOS:(length(Yh)-h)){
YhRealized <- Yh[jt + h]
qqTarg <- Quant_OOS[jt + h, ]
PitST_OOS[jt + h] <- cumulative_prob(YhRealized, QQ, qqTarg)
}
#OUT OF SAMPLE, UNCONDITIONAL
for (jt in jtFirstOOS:(length(Yh)-h)){
YhRealized <- Yh[jt + h]
qqTarg <- Quantunc_OOS[jt + h, ]
PitSTunc_OOS[jt + h] <- cumulative_prob(YhRealized, QQ, qqTarg)
}
#CALIBRATION OF CONFORMAL QUANTILE REGRESSION
CPitST_IS <- rep(NA, length(Yh))
CPitSTunc_IS <- rep(NA, length(Yh))
CPitST_OOS <- rep(NA, length(Yh))
CPitSTunc_OOS <- rep(NA, length(Yh))
#IN SAMPLE, UNCONDITIONAL
qqTarg <- CQuantunc_IS[nrow(Quantunc_IS), ]
for(i in (h+1):length(Yh)) {
CPitSTunc_IS[i] <- cumulative_prob(Yh[i], QQ,qqTarg)
}
#IN SAMPLE, CONDITIONAL
for (jt in 1:(length(Yh) - h)) {
YhRealized <- Yh[jt + h]
qqTarg <- CQuant_IS[jt + h, ]
CPitST_IS[jt + h] <- cumulative_prob(YhRealized, QQ, qqTarg)
}
#OUT OF SAMPLE, CONDITIONAL
for (jt in jtFirstOOS:(length(Yh)-h)){
YhRealized <- Yh[jt + h]
qqTarg <- CQuant_OOS[jt + h, ]
CPitST_OOS[jt + h] <- cumulative_prob(YhRealized, QQ, qqTarg)
}
#OUT OF SAMPLE, UNCONDITIONAL
for (jt in jtFirstOOS:(length(Yh)-h)){
YhRealized <- Yh[jt + h]
qqTarg <- CQuantunc_OOS[jt + h, ]
CPitSTunc_OOS[jt + h] <- cumulative_prob(YhRealized, QQ, qqTarg)
}
PITtest_env <- new.env()
source("PITtest.r",local = PITtest_env)
rstestboot_env <- new.env()
source("rstestboot.r",local = rstestboot_env)
# PROBABILITY INTEGRAL TRANSFORM (PIT) FOR QUANTILE REGRESSION
rvec <- seq(0, 1, by = 0.001)
zST_ecdf1 <- PITtest_env$PITtest(PitST_OOS, rvec)
# PROBABILITY INTEGRAL TRANSFORM (PIT) FOR  CONFORMAL QUANTILE REGRESSION
rvec <- seq(0, 1, by = 0.001)
CzST_ecdf1 <- PITtest_env$PITtest(CPitST_OOS, rvec)
# Plot PIT for quantile regression vs. conformal quantile regression
plot(rvec, CzST_ecdf1, type = 'l', col = 'blue', xlab = 'tau', ylab = 'Empirical CDF')
lines(rvec, zST_ecdf1, type = 'l', col = 'red')
lines(rvec, rvec , col = 'black',lty=2)
abline(v = QQ, col = "green", lty = 0)
abline(h = QQ, col = "green", lty = 0)
legend('bottomright', legend = c('Conformal Quantile Regression', 'Quantile regression'), cex = 0.5,fill = c('blue', 'red'))
quant_est_cqr <- unique(CzST_ecdf1)[2: (length(unique(CzST_ecdf1))-1)]
quant_est_qr <- unique(zST_ecdf1)[2: (length(unique(zST_ecdf1))-1)]
cat("ERROR CQR: ", sqrt(mean(quant_est_cqr-QQ)^2), "\n")
cat("ERROR QR: ", sqrt(mean(quant_est_qr-QQ)^2), "\n")
