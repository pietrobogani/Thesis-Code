setwd("C:/Users/Pietro/Desktop/Pietro/Politecnico/Tesi/Thesis-Code/ConformalizedQuantileRegressionNOSmoothing")
#--- MODEL IN THE PAPER
# y(t) = GDP % increase in the quarter t
# Yh(t) = 1/4 * (y(t) + y(t-1) + y(t-2) + y(t-3))
# Z(t) <- cbind(1, NFCI(t), y(t))
# Quantile Regression: Yh(t) ~ Z(t-4) = c(1, NFCI(t-4),y(t-4)) # I'm predicting the average of the next 4 time steps
#--- DATA GENERATING PROCESS
#y(t) = µ(t) + exp(h(t)/2) * ε(t)
#h(t) = h(t−1) + η(t), η(t) ∼ N (0, σ^2(h))
#ε(t) = u(t) − E[u(t)], with u(t) ∼ NCT (ν, δ(t)) and with E[u(t)] = c11(ν)*δ(t), if ν > 1
#c11(v) = sqrt(0.5*ν) * Γ(0.5*(ν − 1)) / Γ( 0.5*ν)
#δ(t) = φ*δ(t−1) + β0 + β1*NFCI(t) + ω(t), ω(t) ∼ N (0, σ^2(δ)), |φ| < 1,
#MODIFICATIONS W.R.T THE ORIGINAL PAPER:
#1) I REMOVED  THE CONDITION MEAN µ(t). ITS PARAMETERS ARE NOT SPECIFIED IN THE PAPER. ALSO IN THE APPENDIX THEY RUN A SHORTER SIMULATION WITHOUT IT
#2) I USES NFCI INSTEAD FCI. THEY'RE SIMILAR EVEN THOUGH NOT THE SAME. I USE THE PARAMETER OF FCI INSIDE NFCI.
#3) INITIALIZATION OF δ(0) AND h(0) IS ARBITRARY AND SET TO 0 BY ME
#4) I USE ONLY THE UNITED STATES DATA
#------ PARAMETERS OF THE MODEL TO BE SET
# σ^2(h), ν, φ, β0, β1, σ^2(δ), NFCI(0), δ(0), h(0)
step <- 4 # Other choice is h = 1
T <- 1004 #time length
if (step == 1)
{
sigmah <- 0.04
v <- 9.85
phi <- -0.39
beta0 <- -1.05
beta1 <- -0.85
sigmatheta <- 0.016
} else if (step == 4) {
sigmah <- 0.069
v <- 19.56
phi <- -0.25
beta0 <- -1.47
beta1 <- 0.3
sigmatheta <- 0.017
}
theta <- numeric(T)
theta[1] <- 0 #MY CHOICE
h <- numeric(T)
h[1] <- 0 #MY CHOICE
NFCI <- numeric(T)
NFCI[1] <- 0 #MY CHOICE
library(caret)
library(sn)
library(quantreg)
library(readxl)
library(forecast)
library(SuppDists)
# COMPARISON OF NFCI AND FCI
library(readr)
library(dplyr)
# Load the updated CSV file, correctly handling semicolons as delimiters
d <- read_delim("FCIdata.csv",
delim = ";",
col_names = c("Date_NFCI", "NFCI", "NA1", "FCI", "Date_FCI"),
col_types = cols(Date_NFCI = col_date(format = "%d/%m/%Y"),
NFCI = col_double(),
NA1 = col_skip(),
FCI = col_double(),
Date_FCI = col_date(format = "%d/%m/%y")))
N <- d[!is.na(d[,1]),c(1,2)]
FCI <- d[,c(4,3)]
FCI <- FCI[seq(1, nrow(FCI), by = 3), ]
plot(FCI$Date_FCI,FCI$FCI, col = 'red')
points(N$Date_NFCI, N$NFCI)
#LOAD ORIGINAL DATA
file_path <- "DataVulnerabilityAppendix.xls"
# Read the file
data <- read_excel(file_path)
data <- data[,1:3]
NFCI_real <- data$NFCI
y_real <- data$A191RL1Q225SBEA
#------ Fit an AR(1) model to NFCI, then generate a new time series using the fitted model
fit <- auto.arima(NFCI_real)
# Extract AR(1) coefficient
ar_coefficient <- fit$ar
NFCI <- numeric(T)
NFCI[1] <- -1 #MY CHOICE
# Simulate new values
for(i in 2:T) {
NFCI[i] <- ar_coefficient * NFCI[i-1] + rnorm(1, mean = 0, sd = sqrt(fit$var.pred))
}
View(fit)
fit
#--- MODEL IN THE PAPER
# y(t) = GDP % increase in the quarter t
# Yh(t) = 1/4 * (y(t) + y(t-1) + y(t-2) + y(t-3))
# Z(t) <- cbind(1, NFCI(t), y(t))
# Quantile Regression: Yh(t) ~ Z(t-4) = c(1, NFCI(t-4),y(t-4)) # I'm predicting the average of the next 4 time steps
#--- DATA GENERATING PROCESS
#y(t) = µ(t) +exp(h(t)/2) * ε(t)
#h(t) = h(t−1) + η(t), η(t) ∼ N (0, σ^2(h))
#ε(t) = u(t) − E[u(t)], with u(t) ∼ NCT (ν, δ(t)) and with E[u(t)] = c11(ν)*δ(t), if ν > 1
#c11(v) = sqrt(0.5*ν) * Γ(0.5*(ν − 1)) / Γ( 0.5*ν)
#δ(t) = φ*δ(t−1) + β0 + β1*NFCI(t) + ω(t), ω(t) ∼ N (0, σ^2(δ)), |φ| < 1,
#MODIFICATIONS W.R.T THE ORIGINAL PAPER:
#1) I REMOVED  THE CONDITION MEAN µ(t). ITS PARAMETERS ARE NOT SPECIFIED IN THE PAPER. ALSO IN THE APPENDIX THEY RUN A SHORTER SIMULATION WITHOUT IT
#2) I USES NFCI INSTEAD FCI. THEY'RE SIMILAR EVEN THOUGH NOT THE SAME. I USE THE PARAMETER OF FCI INSIDE NFCI.
#3) INITIALIZATION OF δ(0) AND h(0) IS ARBITRARY AND SET TO 0 BY ME
#4) I USE ONLY THE UNITED STATES DATA
#------ PARAMETERS OF THE MODEL TO BE SET
# σ^2(h), ν, φ, β0, β1, σ^2(δ), NFCI(0), δ(0), h(0)
step <- 4 # Other choice is h = 1
T <- 1004 #time length
if (step == 1)
{
sigmah <- 0.04
v <- 9.85
phi <- -0.39
beta0 <- -1.05
beta1 <- -0.85
sigmatheta <- 0.016
} else if (step == 4) {
sigmah <- 0.069
v <- 19.56
phi <- -0.25
beta0 <- -1.47
beta1 <- 0.3
sigmatheta <- 0.017
}
theta <- numeric(T)
theta[1] <- 0 #MY CHOICE
h <- numeric(T)
h[1] <- 0 #MY CHOICE
NFCI <- numeric(T)
NFCI[1] <- 0 #MY CHOICE
library(caret)
library(sn)
library(quantreg)
library(readxl)
library(forecast)
library(SuppDists)
# COMPARISON OF NFCI AND FCI
library(readr)
library(dplyr)
# Load the updated CSV file, correctly handling semicolons as delimiters
d <- read_delim("FCIdata.csv",
delim = ";",
col_names = c("Date_NFCI", "NFCI", "NA1", "FCI", "Date_FCI"),
col_types = cols(Date_NFCI = col_date(format = "%d/%m/%Y"),
NFCI = col_double(),
NA1 = col_skip(),
FCI = col_double(),
Date_FCI = col_date(format = "%d/%m/%y")))
N <- d[!is.na(d[,1]),c(1,2)]
FCI <- d[,c(4,3)]
FCI <- FCI[seq(1, nrow(FCI), by = 3), ]
plot(FCI$Date_FCI,FCI$FCI, col = 'red')
points(N$Date_NFCI, N$NFCI)
#LOAD ORIGINAL DATA
file_path <- "DataVulnerabilityAppendix.xls"
# Read the file
data <- read_excel(file_path)
data <- data[,1:3]
NFCI_real <- data$NFCI
y_real <- data$A191RL1Q225SBEA
#------ Fit an AR(1) model to NFCI, then generate a new time series using the fitted model
fit <- ar(NFCI_real, order.max = 1)
# Extract AR(1) coefficient
ar_coefficient <- fit$ar
NFCI <- numeric(T)
NFCI[1] <- -1 #MY CHOICE
# Simulate new values
for(i in 2:T) {
NFCI[i] <- ar_coefficient * NFCI[i-1] + rnorm(1, mean = 0, sd = sqrt(fit$var.pred))
}
#------ Generate ω(t), η(t)
omega <- rnorm(T, 0, sigmatheta)
nu <- rnorm(T, 0, sigmah)
#------ G2nerate δ(t) = φ*δ(t−1) + β0 + β1*NFCI(t) + ω(t)
for(t in 2:T) {
theta[t] <- phi * theta[t-1] + beta0 + beta1*NFCI[t] + omega[t]
}
#------ Compute c11(v) and E[u(t)]
c11 <- sqrt(0.5 * v) * gamma(0.5 * (v - 1)) / gamma(0.5 * v)
Expv <- numeric(T)
for(t in 1:T) {
Expv[t] <- c11 * theta[t]
}
#------ Generate u(t) ∼ NCT (ν, δ(t))
u <- numeric(T)
for(t in 1:T) {
#u[t] <- rnct(n = 1, df = v, ncp = theta[t])
u[t] <- rt(n = 1, df = v, ncp = theta[t])
}
#------ Generate ε(t) = u(t) − E[u(t)]
eps <- u - Expv
#------ Generate h(t) = h(t−1) + η(t)
for(t in 2:T) {
h[t] <- h[t-1] + nu[t]
}
#------ Generate y(t) = exp(h(t)/2) * ε(t), which is my GDP growth
y <- exp(h/2) * eps
Yh <- stats::filter(y, rep(1/step, step), sides=1) # moving average of the h past values
#COMPARE MY SYNTHETIC DATA AND THE ORIGINAL ONE
hist(y, xlim = range(c(y, y_real)))
hist(y_real, xlim = range(c(y, y_real)))
hist(NFCI, xlim = range(c(NFCI, NFCI_real)))
hist(NFCI_real, xlim = range(c(NFCI, NFCI_real)))
Z <- cbind(1, NFCI, y)
ZGDPonly <- cbind(1, y)
Z <- as.matrix(Z)
ZGDPonly <- as.matrix(ZGDPonly)
#CREATE TEST AND TRAINING SET  ------> Non ha senso, faccio già in-sample e out-of-sample
# set.seed(123) # Setting a seed for reproducibility
# trainIndex <- createDataPartition(Yh, p = 0.8, list = FALSE) #80% train, 20% test
# Yh_train <- Yh[trainIndex]
# Yh_test <- Yh[-trainIndex]
# Z_train <- Z[trainIndex,]
# Z_test <- Z[-trainIndex,]
#QUANTILE REGRESSION (CORRETTA, UGUALE AL PAPER ORIGINALE)
QQ <- seq(0.05, 0.95, by = 0.025) #vector of quantiles I'll do quantile regression on
QQ <- c(0.01, QQ, 0.99)
jtFirstOOS <- 500 #First index for out-of-sample computations
Quant_IS <- matrix(NA, nrow(Z), length(QQ))
QuantGDPonly_IS <- matrix(NA, nrow(Z), length(QQ))
Quantunc_IS <- matrix(NA, nrow(Z), length(QQ))
Quant_OOS <- matrix(NA, nrow(Z), length(QQ))
QuantGDPonly_OOS <- matrix(NA, nrow(Z), length(QQ))
Quantunc_OOS <- matrix(NA, nrow(Z), length(QQ))
#IN SAMPLE
for (jq in 1:length(QQ)) {
#FULL CONDITIONAL
QRfull <- rq(Yh[(step+1):length(Yh)] ~ Z[1:(length(Yh) - step),-1], tau=QQ[jq])
Quant_IS[(step+1):length(Yh), jq] <- as.vector(Z[1:(length(Yh) - step),] %*% coef(QRfull))
#CONDITIONAL, GDP ONLY
QR <- rq(Yh[(step+1):length(Yh)] ~ ZGDPonly[1:(length(Yh) - step),-1], tau=QQ[jq])
QuantGDPonly_IS[(step+1):length(Yh), jq] <- as.vector(ZGDPonly[1:(length(Yh) - step),] %*% coef(QR))
#UNCONDITIONAL
# suppressWarnings(QRunc <- rq(Yh[(step+1):length(Yh)] ~ 1, tau=QQ[jq]))
# Quantunc_IS[(step+1):length(Yh), jq] <- rep(coef(QRunc), nrow(Z) - step) #columns has to be equal
}
#OUT OF SAMPLE
for (jt in jtFirstOOS:(length(Yh)- step)) {
for (jq in 1:length(QQ)) {
#FULL CONDITIONAL
QRfull <- rq(Yh[(step+1):jt] ~ Z[1:(jt - step),-1], tau=QQ[jq])
Quant_OOS[jt + step, jq] <- Z[jt, ] %*% coef(QRfull)
#CONDITIONAL, GDP ONLY
QR <- rq(Yh[(step+1):jt] ~ ZGDPonly[1:(jt - step),-1], tau=QQ[jq])
QuantGDPonly_OOS[jt + step, jq] <- ZGDPonly[jt, ] %*% coef(QR)
#UNCONDITIONAL
# suppressWarnings(QRunc <- rq(Yh[(step+1) : jt] ~ 1, QQ[jq]))
# Quantunc_OOS[jt + step, jq] <- coef(QRunc)
}
}
# CONFORMALIZED QUANTILE REGRESSION
#CREATE TEST AND CALIBRATION SETS FOR CQR WITH A 50-50 SPLIT
length <- length(Yh[(step+1):length(Yh)])
Z1 <- Z[1:(length/2),]
Z2 <- Z[(length/2+1):(length(Yh)- step),]
ZGDPonly1 <- ZGDPonly[1:(length/2),]
ZGDPonly2 <- ZGDPonly[(length/2+1):(length(Yh) - step),]
Yh1 <- Yh[(step+1):(length/2+ step)]
Yh2 <- Yh[(length/2+step+1):length(Yh)]
CQuant_IS <- matrix(NA, nrow(Z), length(QQ))
CQuantGDPonly_IS <- matrix(NA, nrow(Z), length(QQ))
CQuantunc_IS <- matrix(NA, nrow(Z), length(QQ))
Q_low <- matrix(NA, nrow(Z), length(QQ))
Q_high <- matrix(NA, nrow(Z), length(QQ))
#IN SAMPLE
for (jq in 1:length(QQ)) {
# FULL CONDITIONAL
Q_low[(step+1):(step + length(Yh1)), jq] <- -Inf
QR <- rq(Yh1 ~ Z1[,-1], tau= QQ[jq])
Q_high[(step+1):(step +length(Yh2)), jq] <- as.vector(Z2 %*% coef(QR))
# Initialize a vector for errors
E_i <- rep(NA, length(Yh2))
# Calculate errors for each point in the test set I2
for (i in 1:length(E_i)) {
E_i[i] <- max(Q_low[step +i, jq] - Yh2[i], Yh2[i] - Q_high[step +i, jq])
}
# Compute Q(QQ[jq])(E, I2) N.B 1 - ?? = QQ[jq]
quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
CQuant_IS[(step+1):length(Yh) ,jq] <- as.vector(Z[1:(length(Yh) - step),] %*% coef(QR)) + quantile_E
#CONDITIONAL, GDP ONLY
Q_low[(step+1):(step + length(Yh1)), jq] <- -Inf
QR <- rq(Yh1 ~ ZGDPonly1[,-1], tau= QQ[jq])
Q_high[(step+1):(step +length(Yh2)), jq] <- as.vector(ZGDPonly2 %*% coef(QR))
# Initialize a vector for errors
E_i <- rep(NA, length(Yh2))
# Calculate errors for each point in the test set I2
for (i in 1:length(E_i)) {
E_i[i] <- max(Q_low[step +i, jq] - Yh2[i], Yh2[i] - Q_high[step +i, jq])
}
# Compute Q(QQ[jq])(E, I2) N.B 1 - ?? = QQ[jq]
quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
CQuantGDPonly_IS[(step+1):length(Yh) ,jq] <- as.vector(ZGDPonly[1:(length(Yh) - step),] %*% coef(QR)) + quantile_E
#UNCONDITIONAL
#   Q_low[(step+1):(step + length(Yh1)), jq] <- -Inf
#
#   suppressWarnings(QRunc <- rq(Yh1 ~ 1, tau= QQ[jq]))
#   Q_high[(step+1):(step +length(Yh2)), jq] <- rep(coef(QRunc), length((step+1):(step + length(Yh2))))
#
#   # Initialize a vector for errors
#   E_i <- rep(NA, length(Yh2))
#
#   # Calculate errors for each point in the test set I2
#   for (i in 1:length(E_i)) {
#     E_i[i] <- max(Q_low[step +i, jq] - Yh2[i], Yh2[i] - Q_high[step +i, jq])
#   }
#
#   # Compute Q(QQ[jq])(E, I2) N.B 1 - ?? = QQ[jq]
#   quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
#
#
#   CQuantunc_IS[(step+1):length(Yh) ,jq] <- rep(coef(QRunc), length(Yh) - step) + quantile_E
}
#OUT OF SAMPLE
CQuant_OOS <- matrix(NA, nrow(Z), length(QQ))
CQuantGDPonly_OOS <- matrix(NA, nrow(Z), length(QQ))
CQuantunc_OOS <- matrix(NA, nrow(Z), length(QQ))
for (jt in jtFirstOOS:(length(Yh)- step)) {
full_length <- length(Yh[(step+1):jt])
test_length = full_length*50/100
Yh1 <- Yh[(step+1):(step +test_length)]
Yh2 <- Yh[(test_length +step+1):jt] #Yh1 and Yh2 correctly have same dimension
Z1 <- Z[1:test_length,]
Z2 <- Z[(test_length+1):(jt- step),] #Z1 and Z2 correctly have same dimension
ZGDPonly1 <- ZGDPonly[1:test_length,]
ZGDPonly2 <- ZGDPonly[(test_length+1):(jt - step),]
for (jq in 1:length(QQ)) {
#FULL CONDITIONAL
Q_low[(step+1):(step +length(Yh1)), jq] <- -Inf
QR <- rq(Yh1 ~ Z1[,-1], tau= QQ[jq])
Q_high[(step+1):(step +length(Yh2)), jq] <- as.vector(Z2 %*% coef(QR))
# Initialize a vector for errors
E_i <- rep(NA, length(Yh2))
# Calculate errors for each point in the test set I2
for (i in 1:length(E_i)) {
E_i[i] <- max(Q_low[step +i, jq] - Yh2[i], Yh2[i] - Q_high[step +i, jq])
}
# Compute Q(QQ[jq])(E, I2) N.B 1 - ?? = QQ[jq]
quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
CQuant_OOS[jt+ step,jq] <- Z[jt,] %*% coef(QR) + quantile_E
#CONDITIONAL, GDP ONLY
Q_low[(step+1):(step +length(Yh1)), jq] <- -Inf
QR <- rq(Yh1 ~ ZGDPonly1[,-1], tau= QQ[jq])
Q_high[(step+1):(step +length(Yh2)), jq] <- as.vector(ZGDPonly2 %*% coef(QR))
# Initialize a vector for errors
E_i <- rep(NA, length(Yh2))
# Calculate errors for each point in the test set I2
for (i in 1:length(E_i)) {
E_i[i] <- max(Q_low[step +i, jq] - Yh2[i], Yh2[i] - Q_high[step +i, jq])
}
# Compute Q(QQ[jq])(E, I2) N.B 1 - ?? = QQ[jq]
quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
CQuantGDPonly_OOS[jt+ step,jq] <- ZGDPonly[jt,] %*% coef(QR) + quantile_E
#UNCONDITIONAL
# Q_low[(step+1):(step +length(Yh1)), jq] <- -Inf
# suppressWarnings(QRunc <- rq(Yh1 ~ 1, tau= QQ[jq]))
# Q_high[(step+1):(step +length(Yh2)), jq] <- rep(coef(QRunc), length((step+1):(step + test_length)))
#
# # Initialize a vector for errors
# E_i <- rep(NA, length(Yh2))
#
# # Calculate errors for each point in the test set I2
# for (i in 1:length(E_i)) {
#   E_i[i] <- max(Q_low[step +i, jq] - Yh2[i], Yh2[i] - Q_high[step +i, jq])
# }
#
# # Compute Q(QQ[jq])(E, I2) N.B 1 - ?? = QQ[jq]
# quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
#
# CQuantunc_OOS[jt+ step ,jq] <- coef(QRunc) + quantile_E
}
}
#CALIBRATION OF QUANTILE REGRESSION
# This function returns the cumulative probability for a given value X, assuming a step function as CDF
cumulative_prob <- function(X, quantiles, values) {
if (length(values[values <= X]) == 0) {
return(0) # If X is less than the smallest value, the cumulative probability is 0
}
max_value_not_exceeding_X <- max(values[values <= X], na.rm = TRUE)
quantile_index <- which(values == max_value_not_exceeding_X)
if (length(quantile_index) == 0) {
return(1) # If X is greater than all values, return the maximum cumulative probability
}
return(quantiles[min(quantile_index)])
}
PitST_IS <- rep(NA, length(Yh))
PitSTGDPonly_IS <- rep(NA, length(Yh))
PitSTunc_IS <- rep(NA, length(Yh))
PitST_OOS <- rep(NA, length(Yh))
PitSTGDPonly_OOS <- rep(NA, length(Yh))
PitSTunc_OOS <- rep(NA, length(Yh))
#IN SAMPLE, FULL CONDITIONAL
for (jt in 1:(length(Yh) - step)) {
YhRealized <- Yh[jt + step]
qqTarg <- Quant_IS[jt + step, ]
PitST_IS[jt + step] <- cumulative_prob(YhRealized, QQ, qqTarg)
}
#IN SAMPLE, CONDITIONAL GDP ONLY
for (jt in 1:(length(Yh) - step)) {
YhRealized <- Yh[jt + step]
qqTarg <- QuantGDPonly_IS[jt + step, ]
PitSTGDPonly_IS[jt + step] <- cumulative_prob(YhRealized, QQ, qqTarg)
}
#IN SAMPLE, UNCONDITIONAL
# qqTarg <- Quantunc_IS[nrow(Quantunc_IS), ]
#
# for(i in (step+1):length(Yh)) {
#    PitSTunc_IS[i] <- cumulative_prob(Yh[i], QQ, qqTarg)
# }
#
#OUT OF SAMPLE, FULL CONDITIONAL
for (jt in jtFirstOOS:(length(Yh)- step)){
YhRealized <- Yh[jt + step]
qqTarg <- Quant_OOS[jt + step, ]
PitST_OOS[jt + step] <- cumulative_prob(YhRealized, QQ, qqTarg)
}
#OUT OF SAMPLE, CONDITIONAL GDP ONLY
for (jt in jtFirstOOS:(length(Yh)- step)){
YhRealized <- Yh[jt + step]
qqTarg <- QuantGDPonly_OOS[jt + step, ]
PitSTGDPonly_OOS[jt + step] <- cumulative_prob(YhRealized, QQ, qqTarg)
}
#OUT OF SAMPLE, UNCONDITIONAL
# for (jt in jtFirstOOS:(length(Yh)- step)){
#
#     YhRealized <- Yh[jt + step]
#     qqTarg <- Quantunc_OOS[jt + step, ]
#     PitSTunc_OOS[jt + step] <- cumulative_prob(YhRealized, QQ, qqTarg)
#
# }
#CALIBRATION OF CONFORMAL QUANTILE REGRESSION
CPitST_IS <- rep(NA, length(Yh))
CPitSTGDPonly_IS <- rep(NA, length(Yh))
CPitSTunc_IS <- rep(NA, length(Yh))
CPitST_OOS <- rep(NA, length(Yh))
CPitSTGDPonly_OOS <- rep(NA, length(Yh))
CPitSTunc_OOS <- rep(NA, length(Yh))
#IN SAMPLE, FULL CONDITIONAL
for (jt in 1:(length(Yh) - step)) {
YhRealized <- Yh[jt + step]
qqTarg <- CQuant_IS[jt + step, ]
CPitST_IS[jt + step] <- cumulative_prob(YhRealized, QQ, qqTarg)
}
#IN SAMPLE, CONDITIONAL GDP ONLY
for (jt in 1:(length(Yh) - step)) {
YhRealized <- Yh[jt + step]
qqTarg <- CQuantGDPonly_IS[jt + step, ]
CPitSTGDPonly_IS[jt + step] <- cumulative_prob(YhRealized, QQ, qqTarg)
}
#IN SAMPLE, UNCONDITIONAL
#
# qqTarg <- CQuantunc_IS[nrow(Quantunc_IS), ]
#
# for(i in (step+1):length(Yh)) {
#    CPitSTunc_IS[i] <- cumulative_prob(Yh[i], QQ,qqTarg)
# }
#
#OUT OF SAMPLE, FULL CONDITIONAL
for (jt in jtFirstOOS:(length(Yh)- step)){
YhRealized <- Yh[jt + step]
qqTarg <- CQuant_OOS[jt + step, ]
CPitST_OOS[jt + step] <- cumulative_prob(YhRealized, QQ, qqTarg)
}
#OUT OF SAMPLE, CONDITIONAL GDP ONLY
for (jt in jtFirstOOS:(length(Yh)- step)){
YhRealized <- Yh[jt + step]
qqTarg <- CQuantGDPonly_OOS[jt + step, ]
CPitSTGDPonly_OOS[jt + step] <- cumulative_prob(YhRealized, QQ, qqTarg)
}
#OUT OF SAMPLE, UNCONDITIONAL
# for (jt in jtFirstOOS:(length(Yh)- step)){
#
#     YhRealized <- Yh[jt + step]
#     qqTarg <- CQuantunc_OOS[jt + step, ]
#     CPitSTunc_OOS[jt + step] <- cumulative_prob(YhRealized, QQ, qqTarg)
#
# }
#
PITtest_env <- new.env()
source("PITtest.r",local = PITtest_env)
rstestboot_env <- new.env()
source("rstestboot.r",local = rstestboot_env)
# PROBABILITY INTEGRAL TRANSFORM (PIT) FOR QUANTILE REGRESSION, FULL CONDITIONAL MODEL
rvec <- seq(0, 1, by = 0.001)
zST_ecdf1 <- PITtest_env$PITtest(PitST_OOS, rvec)
# PROBABILITY INTEGRAL TRANSFORM (PIT) FOR CONFORMAL QUANTILE REGRESSION, FULL CONDITIONAL MODEL
rvec <- seq(0, 1, by = 0.001)
CzST_ecdf1 <- PITtest_env$PITtest(CPitST_OOS, rvec)
# Plot PIT for quantile regression vs. conformal quantile regression
plot(rvec, CzST_ecdf1, type = 'l', col = 'blue', xlab = 'tau', ylab = 'Empirical CDF', main = 'Full Conditional Model')
lines(rvec, zST_ecdf1, type = 'l', col = 'red')
lines(rvec, rvec , col = 'black',lty=2)
abline(v = QQ, col = "green", lty = 0)
abline(h = QQ, col = "green", lty = 0)
legend('bottomright', legend = c('Conformal Quantile Regression', 'Quantile regression'), cex = 1,fill = c('blue', 'red'))
# PROBABILITY INTEGRAL TRANSFORM (PIT) FOR QUANTILE REGRESSION, GDP ONLY MODEL
rvec <- seq(0, 1, by = 0.001)
zSTGDPonly_ecdf1 <- PITtest_env$PITtest(PitSTGDPonly_OOS, rvec)
# PROBABILITY INTEGRAL TRANSFORM (PIT) FOR  CONFORMAL QUANTILE REGRESSION, GDP ONLY MODEL
rvec <- seq(0, 1, by = 0.001)
CzSTGDPonly_ecdf1 <- PITtest_env$PITtest(CPitSTGDPonly_OOS, rvec)
# Plot PIT for quantile regression vs. conformal quantile regression
plot(rvec, CzSTGDPonly_ecdf1, type = 'l', col = 'blue', xlab = 'tau', ylab = 'Empirical CDF', main = 'GDP ONLY MODEL')
lines(rvec, zSTGDPonly_ecdf1, type = 'l', col = 'red')
lines(rvec, rvec , col = 'black',lty=2)
abline(v = QQ, col = "green", lty = 0)
abline(h = QQ, col = "green", lty = 0)
legend('bottomright', legend = c('Conformal Quantile Regression', 'Quantile regression'), cex = 1,fill = c('blue', 'red'))
quant_est_cqr <- unique(CzST_ecdf1)[2: (length(unique(CzST_ecdf1))-1)]
quant_est_qr <- unique(zST_ecdf1)[2: (length(unique(zST_ecdf1))-1)]
cat("ERROR CQR, FULL CONDITIONAL MODEL: ", sqrt(mean(quant_est_cqr - QQ)^2), "\n")
cat("ERROR QR, FULL CONDITIONAL MODEL: ", sqrt(mean(quant_est_qr - QQ)^2), "\n")
quant_est_cqrGDP <- unique(CzSTGDPonly_ecdf1)[2: (length(unique(CzSTGDPonly_ecdf1))-1)]
quant_est_qrGDP <- unique(zSTGDPonly_ecdf1)[2: (length(unique(zSTGDPonly_ecdf1))-1)]
cat("ERROR CQR, GDP ONLY MODEL: ", sqrt(mean(quant_est_cqrGDP - QQ)^2), "\n")
cat("ERROR QR, GDP ONLY MODEL: ", sqrt(mean(quant_est_qrGDP - QQ)^2), "\n")
