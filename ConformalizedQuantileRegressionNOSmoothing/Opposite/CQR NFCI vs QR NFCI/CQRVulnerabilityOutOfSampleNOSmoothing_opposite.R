
# Install and load necessary packages
library(quantreg)
library(lubridate)
library(pracma)
library(readxl)
library(sn)
library(parallel)

# Clear workspace 
rm(list = ls())

# Load the functions
source("C:/Users/Pietro/Desktop/Pietro/Politecnico/Tesi/Thesis-Code/functions.R")

PITtest_env <- new.env()
source("PITtest.r",local = PITtest_env)

rstestboot_env <- new.env()
source("rstestboot.r",local = rstestboot_env)




# Set forecast horizon (run script separately for h = 1 and h = 4)
h <- 1

loadsavedresults = FALSE; # If I ran code already results are stored in ResOOS_H11 and ResOOS_H14, in that case, set = TRUE


# Graphics settings - R's graphics system differs from MATLAB's, so some modifications are necessary
par(mfrow = c(1, 1))  # Reset plot window to single pane


# Load data 
file_path <- "DataVulnerabilityAppendix.xls"

# Read the file
data <- read_excel(file_path)
data <- data[,1:3]
hist(data$A191RL1Q225SBEA)
# Filter data for 1973Q1-2015Q4
colnames(data)[1] <- "Time"
data$Time <- as.Date(data$Time)


# Subset the data
data <- data[data$Time >= as.Date("1973-01-01") & data$Time <= as.Date("2015-10-01"), ]
X <- data[,2:3]
Time <- data$Time


# Set forecast settings
#QQ <- seq(0.05, 0.95, by = 0.05)
QQ <- seq(0.01, 0.99, by = 0.01) #Let's try a much more fine grid 
#QQ <- c(0.01, QQ, 0.99) # dst function returns too many zeros. This should help
deltaYY <- 0.1
YY <- seq(-20, 20, by = deltaYY)
jtFirstOOS <- which(year(data$Time) == 1993 & month(data$Time) == 1)
indices <- which(QQ %in% c(0.05, 0.25, 0.5, 0.75, 0.95))
jq05 <- indices[1]
jq25 <- indices[2]
jq50 <- indices[3]
jq75 <- 15 #couldn't automatically translate from MATLAB, I set it manually
jq95 <- indices[4] #couldn't automatically translate from MATLAB, I set it manually

# Construct average growth rates
y <- X$A191RL1Q225SBEA
Yh <- matrix(0, nrow=length(y), ncol=4)


Yh <- stats::filter(y, rep(1/h, h), sides=1) #If h = 1, y = Yh
if (h>1){
  Yh[1:(h-1)] <- NA
}
hist(Yh)


#Construct matrices of regressors
Z <- cbind(1, X[,2], y)
ZGDPonly <- cbind(1, y)
Z <-as.matrix(Z)


# Get length of Time and QQ/YY
len_time <- length(data$Time)
len_qq <- length(QQ)
len_yy <- length(YY)

# Initialize matrices to store forecasts
{
# Raw QQ
YQ_NaNs <- matrix(NA, len_time, len_qq)
#YQ_low_adj_ISCO <- YQ_NaNs #IN the original script I've just YQ_ISCO, because I do a point estimate of the quantile. Here I do a confidence interval estimation and I need 2
#YQ_high_adj_ISCO <- YQ_NaNs
YQ_low_ISCO <- YQ_NaNs
YQ_high_ISCO <- YQ_NaNs
YQ_ISCO <- YQ_NaNs
#YQ_low_adj_OOSCO <- YQ_NaNs 
#YQ_high_adj_OOSCO <- YQ_NaNs
YQ_low_OOSCO <- YQ_NaNs
YQ_high_OOSCO <- YQ_NaNs
YQ_OOSCO <- YQ_NaNs
YQ_lowGDPonly_ISCO <- YQ_NaNs
YQ_highGDPonly_ISCO <- YQ_NaNs
YQGDPonly_ISCO <- YQ_NaNs
YQGDPonly_OOSCO <- YQ_NaNs
YQunc_ISCO <- YQ_NaNs
YQunc_OOSCO <- YQ_NaNs
YQunclow_ISCO <- YQ_NaNs
YQunchigh_ISCO <- YQ_NaNs
YQGDPonly_high_OOSCO <- YQ_NaNs
YQGDPonly_low_OOSCO <- YQ_NaNs
YQunclow_OOSCO <- YQ_NaNs
YQunchigh_OOSCO <- YQ_NaNs

YQunchigh_OOSCO <- YQ_NaNs
YQunclow_OOSCO <- YQ_NaNs


# PDFs (evaluated over grid)
P_NaNs <- matrix(NA, len_time, len_yy)
PST_ISCO <- P_NaNs
PST_OOSCO <- P_NaNs
PSTGDPonly_ISCO <- P_NaNs
PSTGDPonly_OOSCO <- P_NaNs
PSTunc_ISCO <- P_NaNs
PSTunc_OOSCO <- P_NaNs

# Smoothed QQ
Q_NaNs <- matrix(NA, len_time, len_qq)
QST_ISCO <- Q_NaNs
QST_OOSCO <- Q_NaNs
QSTGDPonly_ISCO <- Q_NaNs
QSTGDPonly_OOSCO <- Q_NaNs
QSTunc_ISCO <- Q_NaNs
QSTunc_OOSCO <- Q_NaNs

# CDFs (evaluated over grid)
C_NaNs <- matrix(NA, len_time, len_yy)
CST_ISCO <- C_NaNs
CST_OOSCO <- C_NaNs
CSTGDPonly_ISCO <- C_NaNs
CSTGDPonly_OOSCO <- C_NaNs
CSTunc_ISCO <- C_NaNs
CSTunc_OOSCO <- C_NaNs

# Skewed t-distribution parameters
STpar_NaNs <- matrix(NA, len_time, 4)
STpar_ISCO <- STpar_NaNs
STpar_OOSCO <- STpar_NaNs
STparGDPonly_ISCO <- STpar_NaNs
STparGDPonly_OOSCO <- STpar_NaNs
STparunc_ISCO <- STpar_NaNs
STparunc_OOSCO <- STpar_NaNs

# Predictive scores
Score_NaNs <- rep(NA, len_time)
ScoreST_ISCO <- Score_NaNs
ScoreST_OOSCO <- Score_NaNs
ScoreSTGDPonly_ISCO <- Score_NaNs
ScoreSTGDPonly_OOSCO <- Score_NaNs
ScoreSTunc_ISCO <- Score_NaNs
ScoreSTunc_OOSCO <- Score_NaNs

# Probability integral transforms
Pit_NaNs <- rep(NA, len_time)
PitST_ISCO <- Pit_NaNs
PitST_OOSCO <- Pit_NaNs
PitSTGDPonly_ISCO <- Pit_NaNs
PitSTGDPonly_OOSCO <- Pit_NaNs
PitSTunc_ISCO <- Pit_NaNs
PitSTunc_OOSCO <- Pit_NaNs

# Left entropy
Entropy_NaNs <- rep(NA, len_time)
LeftEntropy_ISCO <- Entropy_NaNs
LeftEntropy_OOSCO <- Entropy_NaNs

#Split creating I1 and I2
full_length <- length(Yh[(h + 1):length(Yh)])

#Let's do a 75-25 split

test_length <- full_length*50/100

#permuted_indices <- c(1,2,3,4,sample((h+1):length(Yh))) #if you want to permute
permuted_indices <- c(1:length(Yh)) # if you don't want to permute

Yh_perm <- Yh[permuted_indices]
Z_perm <- Z[permuted_indices,]
ZGDPonly_perm <- ZGDPonly[permuted_indices,]
Yh1 <- Yh_perm[(h+1):(h+test_length)]
Yh2 <- Yh_perm[(h+1+test_length):length(Yh)]
Z1 <- Z_perm[1:(test_length),]
Z2 <- Z_perm[(test_length+1):(length(Yh) - h),]
ZGDPonly1 <- ZGDPonly_perm[1:test_length,]
ZGDPonly2 <- ZGDPonly_perm[(test_length+1):(length(Yh) - h),]
}

if (loadsavedresults == FALSE) {
  
#-------------------    %% In-sample estimation of conditional QQ

for (jq in 1:length(QQ)) {
  
  #CQR is built for intervals, not QQ. Thus I create a prediction interval of the form [-Inf, quantile X] creating a prediction interval with
  #confidence X %
  
  
  #------ Conformalized Quantile regression with both NFCI and GDP
  
  YQ_high_ISCO[(h + 1):(h + test_length), jq] <- Inf 
  
  b_high <- rq(Yh1 ~ Z1[,-1], tau= (1-QQ[jq]))
  YQ_low_ISCO[(h + 1):(h + full_length-test_length), jq] <- as.vector(Z2 %*% coef(b_high)) 

  
  # Initialize a vector for errors
  E_i <- rep(NA, length(Yh2))
  
  # Calculate errors for each point in the test set I2
  for (i in 1:length(E_i)) {
    E_i[i] <- max(YQ_low_ISCO[h + i, jq] - Yh2[i], Yh2[i] - YQ_high_ISCO[h + i, jq])
  }
  
  # Compute Q(QQ[jq])(E, I2) N.B 1 - ?? = QQ[jq]
  quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
  
  YQ_ISCO[(h + 1):length(Yh), jq] <- as.vector(Z[1:(length(Yh) - h),] %*% coef(b_high)) - quantile_E
  
  
  
  #------ Conformalized Quantile regression with GDP only
  
  YQ_highGDPonly_ISCO[(h + 1):(h + test_length), jq] <- Inf 
  
  b_highGDPonly <- rq(Yh1 ~ ZGDPonly1[,-1], tau= (1-QQ[jq]))
  YQ_lowGDPonly_ISCO[(h + 1):(h + full_length-test_length), jq] <- as.vector(ZGDPonly2 %*% coef(b_highGDPonly)) 

  # Initialize a vector for errors
  E_i <- rep(NA, length(Yh2))
  
  # Calculate errors for each point in the test set I2
  for (i in 1:length(E_i)) {
    E_i[i] <- max(YQ_lowGDPonly_ISCO[h + i, jq] - Yh2[i], Yh2[i] - YQ_highGDPonly_ISCO[h + i, jq])
  }
  
  # Compute Q(QQ[jq])(E, I2) N.B 1 - ?? = QQ[jq]
  quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
  
  YQGDPonly_ISCO[(h + 1):length(Yh), jq] <- as.vector(ZGDPonly[1:(length(Yh) - h),] %*% coef(b_highGDPonly)) - quantile_E
  
  
  
  #------ Unconditional QQ (conformalized quantile regression on constant)
  
  YQunchigh_ISCO[(h + 1):(h + test_length), jq] <-  Inf 
  
  bunc_high <- rq(Yh1 ~ 1, tau=(1-QQ[jq]))
  YQunclow_ISCO[(h + 1):(h + test_length), jq] <- rep(coef(bunc_high), length((h + 1):(h + test_length)))

  # Initialize a vector for errors
  E_i <- rep(NA, length(Yh2))
  
  # Calculate errors for each point in the test set I2
  for (i in 1:length(E_i)) {
    E_i[i] <- max(YQunclow_ISCO[h + i, jq] - Yh2[i], Yh2[i] - YQunchigh_ISCO[h + i, jq])
  }
  
  # Compute Q(QQ[jq])(E, I2) N.B 1 - ?? = QQ[jq]
  quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
  
  YQunc_ISCO[(h + 1):length(Yh), jq] <- rep(coef(bunc_high), length(Time) - h) - quantile_E
}


#---------    %% Fit skewed-t distribution for in-sample unconditional QQ

{
    # Fit skewed-t distribution for in-sample unconditional QQ
  qqTarg <- YQunc_ISCO[nrow(YQunc_ISCO), ]

  
  # Assign values to matrices based on the skewed-t fit
  densities <- dst(YY, QQ, qqTarg) # PROBLEMA! visto che ho solo quantili empirici, sotto quantile 0.05 e sopra 0.95 assegno densità =0. Cosa che con smoothing non succede. Come risolvere?
  replicated_matrix <- matrix(rep(densities, each = length(Time) - h), ncol = length(densities))
  PSTunc_ISCO[(h + 1):nrow(PSTunc_ISCO), ] <- replicated_matrix #Giusto, ma tanti 0, forse troppi che danno problemi
  
  
  densities <- qst(QQ, qqTarg) #diverso dall'originale che invece dava i quantili dopo smoothing
  replicated_matrix <- matrix(rep(densities, each = length(Time) - h), ncol = length(densities))
  QSTunc_ISCO[(h + 1):nrow(QSTunc_ISCO), ] <- replicated_matrix #giusto
  
  
  densities <- pst(YY, QQ, qqTarg)
  replicated_matrix <- matrix(rep(densities, each = length(Time) - h), ncol = length(densities))
  CSTunc_ISCO[(h + 1):nrow(CSTunc_ISCO), ] <- replicated_matrix #Credo sbagliato
  
  
  #STparunc_ISCO[(h + 1):nrow(STparunc_ISCO), ] <- matrix(rep(c(lc, sc, sh, df), times = length(Time) - h), 
  #                                                   nrow = length(Time) - h, 
  #                                                   byrow = TRUE)
  #Questo semplicemente salva i parametri, non mi serve più
  
  
  ScoreSTunc_ISCO[(h + 1):length(Yh)] <- dst(Yh[(h + 1):length(Yh)], QQ, qqTarg) 
  PitSTunc_ISCO[(h + 1):length(Yh)] <- pst(Yh[(h + 1):length(Yh)], QQ, qqTarg)
  
}

#---------------------    %% Out-of-sample estimation of conditional QQ



for (jt in 1:(length(Time) - h)) { 
  
  
    month_val <- as.numeric(format(Time[jt], "%m"))
    year_val <- as.numeric(format(Time[jt], "%Y"))
    
    if (month_val == 1 && jt >= jtFirstOOS) { #jtFirstOOS is the date since when I start computing Out-of-sample estimations
      cat(sprintf("Computing in-sample and out-of-sample predictive densities in %d", year_val), "\n")
    } else {
      cat(sprintf("Computing in-sample predictive densities in %d", year_val), "\n")
    }
    
    YhRealized <- Yh[jt + h]
    
    qqTarg <- YQ_ISCO[jt + h, ]

    PST_ISCO[jt + h, ] <- dst(YY, QQ, qqTarg) 
    QST_ISCO[jt + h, ] <- qst(QQ, qqTarg)
    CST_ISCO[jt + h, ] <- pst(YY, QQ, qqTarg)
    #STpar_ISCO[jt + h, ] <- c(lc, sc, sh, df)
    ScoreST_ISCO[jt + h ] <- dst(YhRealized, QQ, qqTarg)
    PitST_ISCO[jt + h ] <- pst(YhRealized, QQ, qqTarg)    # is the probability to observe a value < of YhRealized in this distribution 
    
    Temp <- PST_ISCO[jt + h, ] * (YY < QST_ISCO[jt + h, jq50])
    
    non_zero_indexes <- (PSTunc_ISCO[jt + h, ]!= 0) & (PST_ISCO[jt + h, ] != 0)
    
    # Create new vectors with values from those indexes
    PSTunc_ISCO_non_zero <- PSTunc_ISCO[jt + h, ][non_zero_indexes]
    PST_ISCO_non_zero <- PST_ISCO[jt + h, ][non_zero_indexes]
    Temp_non_zero <- Temp[non_zero_indexes]
    
    LeftEntropy_ISCO[jt + h] <- -sum((log(PSTunc_ISCO_non_zero) - log(PST_ISCO_non_zero)) * Temp_non_zero * deltaYY) 
    
    # Similar computations for GDP only
    qqTarg_GDPonly <- YQGDPonly_ISCO[jt + h, ]
    # params <- QQInterpolation_env$QQInterpolation(qqTarg_GDPonly, QQ)
    # lc <- params$lc
    # sc <- params$sc
    # sh <- params$sh
    # df <- params$df
     
    PSTGDPonly_ISCO[jt + h, ] <- dst(YY, QQ, qqTarg_GDPonly)
    QSTGDPonly_ISCO[jt + h, ] <- qst(QQ, qqTarg_GDPonly)
    CSTGDPonly_ISCO[jt + h, ] <- pst(YY, QQ, qqTarg_GDPonly)
    #STparGDPonly_ISCO[jt + h, ] <- c(lc, sc, sh, df)
    ScoreSTGDPonly_ISCO[jt + h] <- dst(YhRealized, QQ, qqTarg_GDPonly)
    PitSTGDPonly_ISCO[jt + h] <- pst(YhRealized, QQ, qqTarg_GDPonly) # is the probability to observe a value < of YhRealized in this distribution 
     
    
    
    if (jt >= jtFirstOOS) {
      if (month(Time[jt]) == 1) {
        cat(sprintf("Now computing the real-time predictive densities in %d", year(Time[jt])), "\n")
      }
      
      for (jq in 1:length(QQ)) {
        #------- Conformalized Quantile Regression with both NFCI and GDP, out-of-sample
        
        
        #Split creating I1 and I2
        full_length <- length(Yh[(h + 1):jt])
        test_length = full_length*50/100
        Yh1 <- Yh[(h+1):(h+test_length)]
        Yh2 <- Yh[(h+1+test_length):jt] #Yh1 and Yh2 correctly have same dimension
        Z1 <- Z[1:test_length,]
        Z2 <- Z[(test_length+1):(jt - h),] #Z1 and Z2 correctly have same dimension
        ZGDPonly1 <- ZGDPonly[1:test_length,]
        ZGDPonly2 <- ZGDPonly[(test_length+1):(jt - h),]
        
        
        #b_low <- rq(Yh1 ~ Z1[,-1], 0.01)
        YQ_high_OOSCO[(h + 1):(h + test_length), jq] <- Inf #as.vector(Z2 %*% coef(b_low)) #at each iteration of jt, it will be overwritten. But it's fine, we just need to extract jt + h row later on
        
        
        b_high <- rq(Yh1 ~ Z1[,-1], tau= (1-QQ[jq])) #Train on I1
        YQ_low_OOSCO[(h + 1):(h + full_length-test_length), jq] <- as.vector(Z2 %*% coef(b_high)) #Evaluate on I2

        # Initialize a vector for errors
        E_i <- rep(NA, length(Yh2))
        
        # Calculate errors for each point in the test set I2
        for (i in 1:length(E_i)) {
          E_i[i] <- max(YQ_low_OOSCO[h + i, jq] - Yh2[i], Yh2[i] - YQ_high_OOSCO[h + i, jq])
        }
        
        # Compute Q(1-alpha)(E, I2)
        quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
        
        # YQ_low_adj_OOSCO[jt + h, jq] <- Z[jt,] %*% coef(b_low) - quantile_E 
        YQ_OOSCO[jt + h, jq] <- Z[jt,] %*% coef(b_high) - quantile_E 
        

        
        #------- Quantile regression with GDP only, out-of-sample
        
        YQGDPonly_high_OOSCO[(h + 1):(h + test_length), jq] <- Inf
        
        
        bGDPonly_high <- rq(Yh1 ~ ZGDPonly1[,-1], tau= (1-QQ[jq])) #Train on I1
        YQGDPonly_low_OOSCO[(h + 1):(h + full_length-test_length), jq] <- as.vector(ZGDPonly2 %*% coef(bGDPonly_high)) #Evaluate on I2
        # Initialize a vector for errors
        E_i <- rep(NA, length(Yh2))
        
        # Calculate errors for each point in the test set I2
        for (i in 1:length(E_i)) {
          E_i[i] <- max(YQGDPonly_low_OOSCO[h + i, jq] - Yh2[i], Yh2[i] - YQGDPonly_high_OOSCO[h + i, jq])
        }
        
        # Compute Q(1-alpha)(E, I2)
        quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
        
        # YQ_low_adj_OOSCO[jt + h, jq] <- Z[jt,] %*% coef(b_low) - quantile_E 
        YQGDPonly_OOSCO[jt + h, jq] <- ZGDPonly[jt,] %*% coef(bGDPonly_high) - quantile_E 
        

        
        
        #------- Quantile regression with Unconditional QQ, out-of-sample
        
        
        YQunchigh_OOSCO[(h + 1):(h + test_length), jq] <-  Inf #rep(coef(bunc_low), length((h + 1):(h + full_length/2)))
        
        bunc_high <- rq(Yh1 ~ 1, tau=(1-QQ[jq]))
        YQunclow_OOSCO[(h + 1):(h + test_length), jq] <- rep(coef(bunc_high), length((h + 1):(h + test_length)))

        # Initialize a vector for errors
        E_i <- rep(NA, length(Yh2))
        
        # Calculate errors for each point in the test set I2
        for (i in 1:length(E_i)) {
          E_i[i] <- max(YQunclow_OOSCO[h + i, jq] - Yh2[i], Yh2[i] - YQunchigh_OOSCO[h + i, jq])
        }
        
        # Compute Q(1-??)(E, I2)
        quantile_E <- quantile(E_i, pmin(1, pmax(0, (QQ[jq]) * (1 + 1/length(Yh2)))))
        
        YQunc_OOSCO[jt + h, jq] <- coef(bunc_high) - quantile_E
        
      }
      
      #params <- QQInterpolation_env$QQInterpolation(YQ_OOSCO[jt + h, ], QQ) #YQ_OOSCO[jt + h, ] is the new qqTarg!
      PST_OOSCO[jt + h, ] <- dst(YY, QQ, rev(YQ_OOSCO[jt + h, ]))
      QST_OOSCO[jt + h, ] <- qst(QQ, rev(YQ_OOSCO[jt + h, ]))
      CST_OOSCO[jt + h, ] <- pst(YY, QQ, rev(YQ_OOSCO[jt + h, ]))
      #STpar_OOSCO[jt + h, ] <- c(params$lc, params$sc, params$sh, params$df)
      ScoreST_OOSCO[jt + h] <- dst(YhRealized, QQ, rev(YQ_OOSCO[jt + h, ]))
      PitST_OOSCO[jt + h] <- pst(YhRealized, QQ, rev(YQ_OOSCO[jt + h, ])) # is the probability to observe a value < of YhRealized in this distribution 
      
      #params_GDPonly <- QQInterpolation_env$QQInterpolation(YQGDPonly_OOSCO[jt + h, ], QQ)
      PSTGDPonly_OOSCO[jt + h, ] <- dst(YY, QQ, rev(YQGDPonly_OOSCO[jt + h, ]))
      QSTGDPonly_OOSCO[jt + h, ] <- qst(QQ, rev(YQGDPonly_OOSCO[jt + h, ]))
      CSTGDPonly_OOSCO[jt + h, ] <- pst(YY, QQ, rev(YQGDPonly_OOSCO[jt + h, ]))
      #STparGDPonly_OOSCO[jt + h, ] <- c(params_GDPonly$lc, params_GDPonly$sc, params_GDPonly$sh, params_GDPonly$df)
      ScoreSTGDPonly_OOSCO[jt + h] <- dst(YhRealized, QQ, rev(YQGDPonly_OOSCO[jt + h, ]))
      PitSTGDPonly_OOSCO[jt + h] <- pst(YhRealized, QQ, rev(YQGDPonly_OOSCO[jt + h, ])) # is the probability to observe a value < of YhRealized in this distribution 
       
      #params_unc <- QQInterpolation_env$QQInterpolation(YQunc_OOSCO[jt + h, ], QQ)
      PSTunc_OOSCO[jt + h, ] <- dst(YY, QQ, rev(YQunc_OOSCO[jt + h, ]))
      QSTunc_OOSCO[jt + h, ] <- qst(QQ, rev(YQunc_OOSCO[jt + h, ]))
      CSTunc_OOSCO[jt + h, ] <- pst(YY, QQ, rev(YQunc_OOSCO[jt + h, ]))
      #STparunc_OOSCO[jt + h, ] <- c(params_unc$lc, params_unc$sc, params_unc$sh, params_unc$df)
      ScoreSTunc_OOSCO[jt + h] <- dst(YhRealized, QQ, rev(YQunc_OOSCO[jt + h, ]))
      PitSTunc_OOSCO[jt + h] <- pst(YhRealized, QQ, rev(YQunc_OOSCO[jt + h, ])) # is the probability to observe a value < of YhRealized in this distribution 
       
      # Compute entropy for skewed t-distribution from quantile regression with GDP and NFCI, out-of-sample
      Temp <- PST_OOSCO[jt + h, ] * (YY < QST_OOSCO[jt + h, jq50])

      non_zero_indexes <- (PSTunc_OOSCO[jt + h, ] != 0) & (PST_OOSCO[jt + h, ] != 0)
      
      # Create new vectors with values from those indexes
      PSTunc_OOSCO_non_zero <- PSTunc_OOSCO[jt + h, ][non_zero_indexes]
      PST_OOSCO_non_zero <- PST_OOSCO[jt + h, ][non_zero_indexes]
      Temp_non_zero <- Temp[non_zero_indexes]
      
      LeftEntropy_OOSCO[jt + h] <- -sum((log(PSTunc_OOSCO_non_zero) - log(PST_OOSCO_non_zero)) * Temp_non_zero * deltaYY)
    }
    
  } 
  

 
  
  # filename <- paste("ResOOSCOnew_H", h, ".RData",sep="")
  #  cat(paste("Saving results to file", filename, "\n"))
  #  
  #  # Save all the variables to the .RData file
  #  save(
  #    YQ_ISCO,      YQ_OOSCO,      YQGDPonly_ISCO,      YQGDPonly_OOSCO,      YQunc_ISCO,      YQunc_OOSCO,
  #    PST_ISCO,     PST_OOSCO,     PSTGDPonly_ISCO,     PSTGDPonly_OOSCO,     PSTunc_ISCO,     PSTunc_OOSCO,
  #    QST_ISCO,     QST_OOSCO,     QSTGDPonly_ISCO,     QSTGDPonly_OOSCO,     QSTunc_ISCO,     QSTunc_OOSCO,
  #    CST_ISCO,     CST_OOSCO,     CSTGDPonly_ISCO,     CSTGDPonly_OOSCO,     CSTunc_ISCO,     CSTunc_OOSCO,
  #    STpar_ISCO,   STpar_OOSCO,   STparGDPonly_ISCO,   STparGDPonly_OOSCO,   STparunc_ISCO,   STparunc_OOSCO,
  #    ScoreST_ISCO, ScoreST_OOSCO, ScoreSTGDPonly_ISCO, ScoreSTGDPonly_OOSCO, ScoreSTunc_ISCO, ScoreSTunc_OOSCO,
  #    PitST_ISCO,   PitST_OOSCO,   PitSTGDPonly_ISCO,   PitSTGDPonly_OOSCO,   PitSTunc_ISCO,   PitSTunc_OOSCO,
  #    LeftEntropy_ISCO, LeftEntropy_OOSCO, 
  #    file=filename
  #  )
   
  }
# 
# 
# #-------------------------------- per caricare dati salvati -----------------------
# 
# filename <- paste("ResOOS_H", h, "_50-50.RData", sep="")
# cat(paste("Loading results from file", filename, "\n"))
# 
# load(filename)
# 
# #-----------------------------------------------------------------------------------






# Figure 10. Out-of-sample Predictions.             

# (a)/(b) QQ
par(mar = c(3, 3, 2, 1))  # Adjust the values as needed (bottom, left, top, right)

plot(Time, YQ_OOSCO[, jq05], type = 'l', col = 'blue', xlab = 'Time', ylab = 'QQ', xlim = range(Time),ylim = c(-20,20))
lines(Time, YQ_OOSCO[, jq50], type = 'l', col = 'blue', lty = 2)
lines(Time, YQ_OOSCO[,jq95], type = 'l', col = 'blue', lty = 3) 
# lines(Time, YQ_ISCO[, jq05], type = 'l', col = 'black', lty = 1)
# lines(Time, YQ_ISCO[, jq50], type = 'l', col = 'black', lty = 2)
# lines(Time, YQ_ISCO[, jq95], type = 'l', col = 'black', lty = 3)
lines(Time, Yh, type = 'l', col = 'red', lty = 2)




# (c)/(d) Downside Entropy        
plot(Time, LeftEntropy_OOSCO, type = 'l', col = 'blue', 
     xlab = 'Time', ylab = 'Entropy', xlim = range(Time))
lines(Time, LeftEntropy_ISCO, type = 'l', col = 'black', lty = 2)



# Figure 11. Out-of-sample Accuracy.   
# (a)/(b) Predictive scores
plot(Time, ScoreST_OOSCO, type = 'l', col = 'blue', xlab = 'Time', ylab = 'Scores')
lines(Time, ScoreSTGDPonly_OOSCO, type = 'l', col = 'black', lty = 2)
legend('topleft', legend = c('GDP and NFCI', 'GDP only'))

# h = 4:> mean(ScoreST_OOSCO - ScoreST_OOSCOpaper, na.rm = TRUE) == 0.004654713. Predictive scores of my model are better. 
# h = 4:> sum(ScoreST_OOSCO - ScoreST_OOSCOpaper, na.rm = TRUE) == 0.4096147. Confirmed by using sum instead of mean
# h = 4:> mean(ScoreSTGDPonly_OOSCO - ScoreSTGDPonly_OOSCO1, na.rm = TRUE) == 0.04962592. Also the model with only GDP performs better
# h = 4:> sum(ScoreSTGDPonly_OOSCO - ScoreSTGDPonly_OOSCO1, na.rm = TRUE) == 4.367081. Confirmed by using sum instead of mean

# h = 1:> mean(ScoreST_OOSCO - ScoreST_OOSCO1, na.rm = TRUE) == 0.01211243 Predictive scores of my model are better. 
# h = 1:> sum(ScoreST_OOSCO - ScoreST_OOSCO1, na.rm = TRUE) == 1.102231 Confirmed by using sum instead of mean
# h = 1:> mean(ScoreSTGDPonly_OOSCO - ScoreSTGDPonly_OOSCO1, na.rm = TRUE) == 0.02495498 Also the model with only GDP performs better
# h = 1:> sum(ScoreSTGDPonly_OOSCO - ScoreSTGDPonly_OOSCO1, na.rm = TRUE) #== 2.270903 Confirmed by using sum instead of mean
plot(ecdf(ScoreSTGDPonly_OOSCO), main="PS ECDF Comparison GDPonly", col="blue", lty=1, lwd=2)
lines(ecdf(ScoreSTGDPonly_OOSCO1), col="red", lty=2, lwd=2)
legend("bottomright", legend=c("Mio", "Paper"), col=c("blue", "red"), lty=c(1, 2), lwd=2)





# (c)/(d): PITs
# The code below was modified from files provided by Barbara Rossi and
# Tatevik Sekhposyan implementing the specification tests for predictive
# densities described in Rossi and Sekhposyan (2017).
rvec <- seq(0, 1, by = 0.001)
zST_ecdf <- PITtest_env$PITtest(PitST_OOSCO, rvec)
CnSS_model <- 1 - mean((zST_ecdf - seq(0, 1, length.out = length(zST_ecdf)))^2) / var(zST_ecdf) # h = 4: 0.67701012121 || h = 1: 0.9366  is the value. 1 is perfect calibrated
mean_squared_diff <- mean((zST_ecdf-rvec)^2) # h = 4: 0.02338473 || h = 1: 0.005109203

zSTGDPonly_ecdf <- PITtest_env$PITtest(PitSTGDPonly_OOSCO, rvec)
CnSS_model_GDPonly <- 1 - mean((zSTGDPonly_ecdf - seq(0, 1, length.out = length(zSTGDPonly_ecdf)))^2) / var(zSTGDPonly_ecdf) # h = 4: 0.872747225 || h = 1: 0.95697 is the value. 1 is perfect calibrated
mean_squared_diff_GDPonly <- mean((zSTGDPonly_ecdf-rvec)^2) # h = 4: 0.009966178 || h = 1: 0.003439986

if (h == 1) {
  # Use asymptotic 5% critical value from Rossi and Sekhposyan (2017): 1.34
  kappa <- 1.34
  kappaGDPonly <- 1.34
  
} else if (h == 4) {
  # Compute bootstrapped 5% critical values
  PITs <- cbind(PitST_OOSCO, PitSTGDPonly_OOSCO)
  PITs <- PITs[(jtFirstOOS + h):nrow(PITs), , drop = FALSE]
  
  #testcritvalues <- matrix(NA, nrow = 1, ncol = 2, dimnames = list(NULL, c('GDP and NFCI', 'GDP only')))
  testcritvalues <- array(NA, dim = c(2, 3, 2))
  
  for (i in 1:2) {
    testcritvalues[,, i] <- round(rstestboot_env$rstestboot(PITs[, i])$critvalues[2] * 100) / 100
  }
  
  kappa <- testcritvalues[1, 2, 1] #different from Matlab due to seed in CVfinalbootstrapInoue
  kappaGDPonly <- testcritvalues[1, 2, 2] #different from Matlab due to seed in CVfinalbootstrapInoue
}

# Plot PIT for full quantile regression vs. quantile regression with GDP only
plot(rvec, zST_ecdf, type = 'l', col = 'blue', xlab = '??', ylab = 'Empirical CDF')
lines(rvec, zSTGDPonly_ecdf, type = 'l', col = 'red')
P <- sum(!is.na(PitST_OOSCO)) #correct for both h = 1 and h = 4

lines(rvec, rvec - (kappa / sqrt(P)), col = 'black',lty=2)
lines(rvec, rvec + (kappa / sqrt(P)), col = 'black',lty=2)
lines(rvec,rvec , col = 'black',lty=2)

legend('bottomright', legend = c('GDP and NFCI', 'GDP only', 'Theoretical and 5% Critical Values'), cex = 0.5,fill = c('blue', 'red', 'black'))

#For hlibrary(



library(ggplot2)
library(dplyr)
library(tidyr)

# Assuming rvec, zST_ecdf, zSTGDPonly_ecdf are vectors of the same length
rvec <- seq(0, 1, by = 0.001)
zST_ecdf <- PITtest_env$PITtest(PitST_OOSCO, rvec)
zSTGDPonly_ecdf <- PITtest_env$PITtest(PitSTGDPonly_OOSCO, rvec)

# Check the contents of zST_ecdf and zSTGDPonly_ecdf
print(head(zST_ecdf))
print(head(zSTGDPonly_ecdf))

data1 <- data.frame(
  tau = rvec,
  full = zST_ecdf,
  GDPonly = zSTGDPonly_ecdf
)

# Create the Line data separately
line_data <- data.frame(tau = rvec, Line = rvec)


# Reshape data for ggplot
data1_long <- data1 %>%
  pivot_longer(cols = -tau, names_to = "Series", values_to = "Value")


# Define a common theme
custom_theme <- theme_minimal() +
  theme(
    axis.title = element_text(face = "bold", size = 14),
    axis.text = element_text(size = 12),
    legend.position = "top",
    plot.background = element_rect(fill = "white", color = NA),
    panel.background = element_rect(fill = "white", color = NA),
    panel.grid.major = element_line(color = "grey80"),
    panel.grid.minor = element_line(color = "grey90")
  )

# Calculate kappa and P
if (h == 1) {
  kappa <- 1.34
} else if (h == 4) {
  PITs <- cbind(PitST_OOSCO, PitSTGDPonly_OOSCO)
  PITs <- PITs[(jtFirstOOS + h):nrow(PITs), , drop = FALSE]
  
  testcritvalues <- array(NA, dim = c(2, 3, 2))
  
  for (i in 1:2) {
    testcritvalues[,, i] <- round(rstestboot_env$rstestboot(PITs[, i])$critvalues[2] * 100) / 100
  }
  
  kappa <- testcritvalues[1, 2, 1]
}

P <- sum(!is.na(PitST_OOSCO))

# Create the data frame for the dashed lines
dashed_lines <- data.frame(
  tau = rvec,
  lower = rvec - (kappa / sqrt(P)),
  upper = rvec + (kappa / sqrt(P))
)

# Plot
plot1 <- ggplot(data1_long, aes(x = tau, y = Value, color = Series, linetype = Series)) +
  geom_line(size = 1) +
  geom_line(data = line_data, aes(x = tau, y = Line), color = "black", linetype = "dashed", size = 1.2, show.legend = FALSE) +
  geom_line(data = dashed_lines, aes(x = tau, y = lower), color = "black", linetype = "dashed", size = 1, show.legend = FALSE) +
  geom_line(data = dashed_lines, aes(x = tau, y = upper), color = "black", linetype = "dashed", size = 1, show.legend = FALSE) +
  scale_color_manual(values = c("full" = "blue", "GDPonly" = "red")) +
  scale_linetype_manual(values = c("full" = "solid", "GDPonly" = "solid")) +
  labs(x = expression(tau), y = 'Empirical CDF') +
  custom_theme +
  guides(color = guide_legend(title = NULL), linetype = guide_legend(title = NULL))

print(plot1)